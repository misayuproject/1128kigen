{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misayuproject/1128kigen/blob/main/try1125.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au9GMhtndzYu",
        "outputId": "45a3d7f1-b0cc-4685-b097-66f774895f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#ドライブの接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1_T2rr4vP-X"
      },
      "source": [
        "11月25日\n",
        "\n",
        "SHAPで特徴量の寄与率を調べたい\n",
        "そのためには、アンサンブルとLightGMBのみの評価と、切り替えられるようにしておきたい。LightGBMのみで一度評価して、それをSHAPで調べて、上位のみにしてアンサンブルかけるとか？\n",
        "\n",
        "とりあえずアンサンブルがきれいに書き直せたので、この後の作戦を考えよう\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRNJVXemAGg9"
      },
      "outputs": [],
      "source": [
        "#　18秒\n",
        "\n",
        "#コアデータ処理\n",
        "import pandas as pd                         # データを表のように扱うライブラリ\n",
        "import numpy as np                          # 数値計算を速くするライブラリ\n",
        "from datetime import datetime               #日付と時刻を扱うための基本的なクラス\n",
        "\n",
        "# テキスト処理と感情分析\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer       #このツールは、テキストで表現されている感情的なトーン（ポジティブ、ネガティブ、ニュートラル）を判断するのに役立ちます。\n",
        "from textblob import TextBlob               # 感情分析などの機能を提供するテキスト処理ライブラリ\n",
        "\n",
        "# 特徴量エンジニアリングと前処理:\n",
        "from scipy.sparse import hstack             # スパース行列(多くのゼロを含むデータを効率的に格納する方法であるスパース行列を操作する)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDFと呼ばれる手法を使用してテキストを数値ベクトルに変換します。これは、ドキュメント内の単語の重要性を表すのに役立ちます。\n",
        "from sklearn.feature_extraction.text import CountVectorizer # テキストデータ内の単語の出現回数を単純にカウントすることによって数値ベクトルを作成\n",
        "from sklearn.decomposition import TruncatedSVD  # 次元削減に使用され、データの特徴の数を減らします。\n",
        "from sklearn.model_selection import train_test_split  # データを訓練用と検証用に分けるために使う。機械学習モデルの性能を評価するために不可欠\n",
        "from sklearn.preprocessing import StandardScaler    # 数値特徴を平均0、分散1になるようにスケーリングすることで標準化します\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder   #テゴリデータを数値形式にエンコードするために使用\n",
        "\n",
        "import gensim.downloader as api             # 事前学習済みモデルをダウンロードするための api をインポート\n",
        "\n",
        "#予測モデルに関するライブラリ\n",
        "import lightgbm as lgb                      # 勾配ブースティングフレームワーク\n",
        "import xgboost as xgb                       # もう1つの強力な勾配ブースティングライブラリ\n",
        "!pip install catboost                       # もう1つの勾配ブースティングライブラリ\n",
        "from catboost import CatBoostRegressor      # CatBoostRegressor は、特にその回帰モデル（連続値の予測）を指します\n",
        "from sklearn.ensemble import RandomForestRegressor  # これは、分類タスクと回帰タスクの両方によく使用\n",
        "from sklearn.model_selection import KFold   #データをk個のフォールド（グループ）に分割し、交差検証を行うためのクラス\n",
        "\"\"\"\n",
        "動作:\n",
        "1.データセットをk個のフォールドに分割します。\n",
        "2.k回の学習と評価を繰り返します。\n",
        "    各回で、k-1個のフォールドを学習データ、残りの1個のフォールドを検証データとして使用します。\n",
        "    学習データでモデルを学習し、検証データで性能を評価します。\n",
        "3.k回の評価結果を平均して、モデルの最終的な性能を評価します。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error # 平均二乗誤差 (MSE) を計算する関数\n",
        "\"\"\"\n",
        "計算式　MSE = (1/n) * Σ(yi - ŷi)^2\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re   #正規表現モジュール re、正規表現は、テキスト内で特定のパターンを検索したり、操作したりするための強力なツールです。\n",
        "\"\"\"\n",
        "re の用途:\n",
        "パターンマッチング: テキスト内で特定のパターン (例えば、メールアドレス、電話番号、日付) を見つける。\n",
        "テキストの置換: テキスト内の特定のパターンを別のテキストに置き換える。\n",
        "テキストの抽出: テキストから特定のパターンに一致する部分を抽出する。\n",
        "データクリーニング: データセット内のテキストデータをクリーニングし、標準化する (例えば、不要な空白を削除する、大文字と小文字を統一する)。\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')  # 不要な警告を表示しない\n",
        "\"\"\"\n",
        "1.import warnings: Pythonに組み込まれているwarningsモジュールをインポートします。このモジュールは、警告メッセージを管理するための機能を提供します。警告メッセージは、エラーほど深刻ではありませんが、潜在的な問題や非推奨の機能の使用などを示すために使われます。\n",
        "2.warnings.simplefilter('ignore'): この行が実際に警告メッセージを非表示にする処理を行います。\n",
        "    warnings.simplefilter() は、警告メッセージに対するフィルターを設定する関数です。\n",
        "    'ignore' という引数を指定することで、全ての警告メッセージを無視するように設定しています。つまり、警告メッセージはコンソールやログに出力されなくなります。\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rcfo6jrpJBTF"
      },
      "outputs": [],
      "source": [
        "#データ読み込みセクション　8秒ーーーーーーーーーーーーーーーー\n",
        "#予測モデルを訓練するためのデータセット\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/train.csv', index_col=0)\n",
        "# 予測モデルに推論（予測)させるデータセット\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/test.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストをクリーニングする関数　preprocess_cleanの定義　12秒\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "def preprocess_clean(train, test, columns):\n",
        "    def clean_text(text):\n",
        "        if pd.isnull(text):\n",
        "            return ''\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        return text\n",
        "\n",
        "    for col in columns:\n",
        "        if col in train.columns:\n",
        "            train[col] = train[col].fillna('').map(clean_text)\n",
        "        else:\n",
        "            print(f\"Warning: Column '{col}' not found in train DataFrame\")\n",
        "\n",
        "        if col in test.columns:\n",
        "            test[col] = test[col].fillna('').map(clean_text)\n",
        "        else:\n",
        "            print(f\"Warning: Column '{col}' not found in test DataFrame\")\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train, test = preprocess_clean(train, test, review_columns)\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessingTime: {processing_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYRwyR5y42LD",
        "outputId": "92b8f8f7-2ec1-4a52-bb95-af023e342cd3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: 2024-11-25 10:37:58.458304\n",
            "End: 2024-11-25 10:38:10.230320\n",
            "ProcessingTime: 0:00:11.772016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwtnrRw9vcq",
        "outputId": "8184a1ef-e3ce-4b79-8a4d-fdfe181a5139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: 2024-11-25 10:48:28.860813\n",
            "add_bow_features  : 2024-11-25 10:48:34.837604 - End\n",
            "add_ngram_features : 2024-11-25 10:48:54.265544 - End\n",
            "add_tfidf_features : 2024-11-25 10:49:06.181150 - End\n",
            "add_embedding_features : 2024-11-25 10:50:53.947584 - End\n",
            "add_polarity_features : 2024-11-25 10:52:24.973822 - End\n",
            "Positive_Review : 2024-11-25 10:52:24.973947 - End\n",
            "add_bow_features  : 2024-11-25 10:52:31.083427 - End\n",
            "add_ngram_features : 2024-11-25 10:52:52.168540 - End\n",
            "add_tfidf_features : 2024-11-25 10:53:03.781793 - End\n",
            "add_embedding_features : 2024-11-25 10:54:52.348736 - End\n",
            "add_polarity_features : 2024-11-25 10:56:20.837588 - End\n",
            "Negative_Review : 2024-11-25 10:56:20.837708 - End\n",
            "preprocess_reviews2 : 2024-11-25 10:56:40.804565 - End\n",
            "ProcessingTime: 0:08:11.943913\n"
          ]
        }
      ],
      "source": [
        "# Positive_ReviewとNegative_Reviewの内容をいろいろな手法で分析する.\n",
        "# BOWN,N-gram,TF-IDFの実行、埋め込み表現　・・・\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "def preprocess_reviews(train, test, columns):\n",
        "\n",
        "    # Bag-of-Words特徴量の追加　add_bow_features関数\n",
        "    \"\"\"\n",
        "    CountVectorizerを使用して、テキストデータを単語の出現回数に基づいた数値ベクトルに変換します。\n",
        "    stop_words='english'で英語のストップワード（一般的な単語）を削除します。\n",
        "    max_features=100で出現頻度が高い上位100単語のみを特徴量として使用します。\n",
        "    生成されたBag-of-Words特徴量は、trainとtestデータフレームに新しいカラムとして追加されます。\n",
        "    \"\"\"\n",
        "    def add_bow_features(train, test, column, max_features=10):\n",
        "        # Bag of Words特徴量の追加\n",
        "        bow = CountVectorizer(stop_words='english', max_features=10)    #max_features=50減らす\n",
        "        # 既にクリーニング済みのカラムデータをそのまま使用\n",
        "        train_bow = bow.fit_transform(train[column]).toarray()  # 変更箇所\n",
        "        test_bow = bow.transform(test[column]).toarray()       # 変更箇所\n",
        "\n",
        "        for i in range(train_bow.shape[1]):\n",
        "            train[f'{column}_bow_{i}'] = train_bow[:, i]\n",
        "            test[f'{column}_bow_{i}'] = test_bow[:, i]\n",
        "\n",
        "        return train, test\n",
        "\n",
        "\n",
        "    # テキストデータから N-gram 特徴量を抽出し、データフレームに追加する関数の定義\n",
        "    \"\"\"\n",
        "    N-gram とは、テキスト中に出現する連続した単語の組み合わせのことです。例えば、「the quick brown fox」という文から、\n",
        "        uni-gram (1-gram): the, quick, brown, fox\n",
        "        bi-gram (2-gram): the quick, quick brown, brown fox\n",
        "        tri-gram (3-gram): the quick brown, quick brown fox\n",
        "    といった N-gram を抽出できます。これらの N-gram を特徴量として使用することで、機械学習モデルはテキストデータのより深い意味を理解できるようになります。\n",
        "    CountVectorizer を使用し、uni-gram と bi-gram を抽出することで、単語の出現頻度だけでなく、単語の組み合わせも考慮した特徴量を作成している。\n",
        "    この関数は、指定されたカラム (column) のテキストデータから N-gram 特徴量を抽出し、データフレームに追加します。\n",
        "    ngram_range: N-gram の範囲を指定します。デフォルトは (1, 2) で、uni-gram と bi-gram を抽出します。\n",
        "    max_features: 追加する特徴量の上限を設定します。デフォルトは 100 で、出現頻度が高い上位 100 個の N-gram のみを特徴量として使用します。\n",
        "    \"\"\"\n",
        "    def add_ngram_features(df, column, ngram_range=(1, 2), max_features=50):  # max_features = 50\n",
        "\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=max_features)  # max_features を設定\n",
        "        # 既にクリーニング済みのカラムデータをそのまま使用\n",
        "        ngram_features = vectorizer.fit_transform(df[column])  # 変更箇所\n",
        "\n",
        "        # 特徴量名をデータフレームに追加\n",
        "        ngram_feature_names = vectorizer.get_feature_names_out()  # 抽出された特徴量の名前を取得します。\n",
        "        for i, feature_name in enumerate(ngram_feature_names):\n",
        "            # 抽出された各 N-gram 特徴量を、新しいカラムとしてデータフレームに追加します。\n",
        "            df[f'{column}_ngram_{feature_name}'] = ngram_features[:, i].toarray().ravel()\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    # TF-IDF特徴量を追加する関数(定義)\n",
        "    \"\"\"\n",
        "    TF-IDFベクトライザーの適用: TfidfVectorizerを使用して、テキストデータをTF-IDF値に基づいた数値ベクトルに変換します。\n",
        "\n",
        "    max_features=1000で出現頻度が高い上位1000単語のみを特徴量として使用します。\n",
        "    stop_words='english'で英語のストップワードを削除します。\n",
        "    特徴量の次元削減: TruncatedSVDを使用して、TF-IDF特徴量の次元数を削減します。\n",
        "\n",
        "    n_components=20で次元数を20に削減します。\n",
        "    random_state=42で結果の再現性を確保します。\n",
        "    特徴量をデータフレームに追加: 生成されたTF-IDF特徴量は、trainとtestデータフレームに新しいカラムとして追加されます。\n",
        "\n",
        "    関数の適用: add_tfidf_features関数を'Positive_Review'と'Negative_Review'カラムに適用し、TF-IDF特徴量を追加します。\n",
        "    \"\"\"\n",
        "    def add_tfidf_features(train, test, column, n_components=100, max_features=100):\n",
        "\n",
        "        # TF-IDFベクトライザーの適用\n",
        "        tfidf = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
        "        tfidf_train = tfidf.fit_transform(train[column])\n",
        "        tfidf_test = tfidf.transform(test[column])\n",
        "\n",
        "        # 特徴量の次元削減\n",
        "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "        svd_train = svd.fit_transform(tfidf_train)\n",
        "        svd_test = svd.transform(tfidf_test)\n",
        "\n",
        "        # 特徴量をデータフレームに追加\n",
        "        for i in range(n_components):\n",
        "            train[f'TFIDF_{column}_{i}'] = svd_train[:, i]\n",
        "            test[f'TFIDF_{column}_{i}'] = svd_test[:, i]\n",
        "\n",
        "        return train, test\n",
        "\n",
        "\n",
        "    # 埋め込み表現をデータフレームに追加する関数定義\n",
        "    def add_embedding_features(df, column, model_name='glove-wiki-gigaword-100', max_features=50): # max_features を引数に追加\n",
        "\n",
        "        # glove-wiki-gigaword-100 という名前の事前学習済みモデル (GloVe) を読み込みます。\n",
        "        # このモデルは、Wikipediaなどの大規模なテキストデータから単語の埋め込み表現を学習しています。\n",
        "        model = api.load(model_name)  # 事前学習済みモデルの読み込み\n",
        "\n",
        "        # テキストを受け取り、その埋め込み表現を返す関数を定義\n",
        "        def get_embedding(text):\n",
        "            words = text.split()    # テキストを単語に分割\n",
        "            embeddings = [model[word] for word in words if word in model]   #各単語の埋め込み表現を事前学習済みモデルから取得\n",
        "\n",
        "            if embeddings:          # 単語の埋め込み表現が存在する場合、それらを平均してテキスト全体の埋め込み表現を計算\n",
        "                return np.mean(embeddings, axis=0)\n",
        "            else:                   # 単語の埋め込み表現が存在しない場合、ゼロベクトルを返す\n",
        "                return np.zeros(model.vector_size)\n",
        "\n",
        "        # get_embedding 関数を df の指定された column ( 'Positive_Review' または 'Negative_Review' ) に適用し、\n",
        "        # 埋め込み表現をデータフレームに変換する\n",
        "        embedding_features = df[column].apply(get_embedding).apply(pd.Series)\n",
        "\n",
        "        # 埋め込み表現の特徴量数を max_features で指定された数に制限します。\n",
        "        embedding_features = embedding_features.iloc[:, :max_features] # 列数を制限\n",
        "\n",
        "        # 埋め込み表現のカラムに名前を付けます (例: 'Positive_Review_embedding_0', 'Positive_Review_embedding_1', ...)。\n",
        "        embedding_features.columns = [f'{column}_embedding_{i}' for i in range(embedding_features.shape[1])]\n",
        "\n",
        "        # 埋め込み表現を元のデータフレームに結合します。\n",
        "        df = pd.concat([df, embedding_features], axis=1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    # 極性と主観性をデータフレームに追加する関数の定義 合計4カラム追加される。\n",
        "    def add_polarity_features(df, column):\n",
        "\n",
        "        # TextBlob を使って、指定された column ( 'Positive_Review' または 'Negative_Review' ) のテキストの極性を計算し、{column}_polarity という名前の新しいカラムに追加します。\n",
        "        df[f'{column}_polarity'] = df[column].apply(lambda x: TextBlob(column).sentiment.polarity)\n",
        "\n",
        "        # 同様に、主観性を計算し、{column}_subjectivity という名前の新しいカラムに追加します。\n",
        "        df[f'{column}_subjectivity'] = df[column].apply(lambda x: TextBlob(column).sentiment.subjectivity)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "    # 5種の関数を呼び出す ['Positive_Review', 'Negative_Review']の二回\n",
        "    \"\"\"\n",
        "    add_ngram_features 関数: データフレーム df に直接カラムを追加するため、return df がなくても元のデータフレームに反映される。\n",
        "    add_embedding_features 関数: 新しいデータフレームを作成して df に代入するため、return df で更新された df を返す必要がある。\n",
        "    \"\"\"\n",
        "    for col in columns:\n",
        "\n",
        "        # add_bow_features関数実行\n",
        "        train, test = add_bow_features(train, test, col, max_features=50)\n",
        "        print(f\"add_bow_features  : {datetime.now()} - End\")\n",
        "\n",
        "        # N-gram 特徴量を抽出関数実行\n",
        "        train = add_ngram_features(train, col, max_features=100)    # 使用例: 上位 〇〇 個の Ngram 特徴量のみを追加\n",
        "        test = add_ngram_features(test, col, max_features=100)     # 使用例: 上位 〇〇 個の Ngram 特徴量のみを追加\n",
        "        print(f\"add_ngram_features : {datetime.now()} - End\")\n",
        "\n",
        "        # TF-IDF特徴量追加関数実行 +200\n",
        "        train, test = add_tfidf_features(train, test, col, max_features=100)\n",
        "        print(f\"add_tfidf_features : {datetime.now()} - End\")\n",
        "\n",
        "        # 埋め込み表現追加関数実行 +200\n",
        "        train = add_embedding_features(train, col, max_features=100)\n",
        "        test = add_embedding_features(test, col, max_features=100)\n",
        "        print(f\"add_embedding_features : {datetime.now()} - End\")\n",
        "\n",
        "        # 極性と主観性を追加する関数実行 +4\n",
        "        train = add_polarity_features(train, col)\n",
        "        test = add_polarity_features(test, col)\n",
        "        print(f\"add_polarity_features : {datetime.now()} - End\")\n",
        "\n",
        "        print(f\"{col} : {datetime.now()} - End\")\n",
        "\n",
        "    # preprocess_reviews関数終わり\n",
        "    return train, test\n",
        "\n",
        "# preprocess_reviews関数の実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train, test = preprocess_reviews(train, test, review_columns)\n",
        "\n",
        "\n",
        "# キーワードを抽出し、特徴量として追加する関数　⁺100\n",
        "def preprocess_reviews2(df, max_features=100):\n",
        "    def extract_keywords(text):\n",
        "        words = text.lower().split()\n",
        "        common_words = ['the', 'and', 'is', 'in', 'it', 'to', 'was', 'i', 'of', 'a', 'this']\n",
        "        keywords = [word for word in words if word not in common_words]\n",
        "        return ' '.join(keywords)\n",
        "\n",
        "    df['Positive_Review_Keywords'] = df['Positive_Review'].apply(extract_keywords)\n",
        "    df['Negative_Review_Keywords'] = df['Negative_Review'].apply(extract_keywords)\n",
        "\n",
        "    # CountVectorizerを使ってキーワードをエンコード（フィーチャースペースを制限）\n",
        "    vectorizer = CountVectorizer(max_features=max_features)\n",
        "\n",
        "    positive_keywords_matrix = vectorizer.fit_transform(df['Positive_Review_Keywords'])\n",
        "    negative_keywords_matrix = vectorizer.fit_transform(df['Negative_Review_Keywords'])\n",
        "\n",
        "    # スパース行列を結合\n",
        "    keywords_matrix = hstack([positive_keywords_matrix, negative_keywords_matrix])\n",
        "\n",
        "    # スパース行列をデータフレームに変換する\n",
        "    keywords_df = pd.DataFrame(keywords_matrix.toarray(), columns=[f'Keyword_{i}' for i in range(keywords_matrix.shape[1])])\n",
        "\n",
        "    # 元のデータフレームに結合\n",
        "    df = pd.concat([df.reset_index(drop=True), keywords_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# キーワードを抽出し、特徴量として追加する関数の実行\n",
        "train = preprocess_reviews2(train, max_features=100)\n",
        "test = preprocess_reviews2(test, max_features=100)\n",
        "print(f\"preprocess_reviews2 : {datetime.now()} - End\")\n",
        "\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessingTime: {processing_time}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49hSgOoNQgRE",
        "outputId": "bdfbec2d-f48e-4f62-d5c2-953c16437548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: 2024-11-25 10:57:08.159458\n",
            "End: 2024-11-25 10:59:06.295808\n",
            "ProcessTime: 0:01:58.136350\n"
          ]
        }
      ],
      "source": [
        "#Review項目以外の特徴量追加　#3、#4，#5\n",
        "#レビュー日付、ホテル名、緯度経度といった情報から新しい特徴量を生成\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "# 3. レビュー日付からの特徴量生成(定義)g\n",
        "def extract_date_features(df, date_column):\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    df['review_weekday'] = df[date_column].dt.weekday   #レビューが投稿された曜日 (0:月曜日, 1:火曜日, ..., 6:日曜日)\n",
        "    df['review_month'] = df[date_column].dt.month       #レビューが投稿された月 (1:1月, 2:2月, ..., 12:12月)\n",
        "    df['review_quarter'] = df[date_column].dt.quarter   #レビューが投稿された四半期 (1:1-3月, 2:4-6月, 3:7-9月, 4:10-12月)\n",
        "    df['review_season'] = df[date_column].dt.month % 12 // 3 + 1    #レビューが投稿された季節 (1:春, 2:夏, 3:秋, 4:冬)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 3．レビュー日付からの特徴量生成(実行)\n",
        "date_column = 'Review_Date'\n",
        "train = extract_date_features(train, date_column)\n",
        "test = extract_date_features(test, date_column)\n",
        "\n",
        "\n",
        "# 4. ホテル名の処理(定義)\n",
        "def preprocess_hotel_names(train, test, column):\n",
        "    train[f'{column}_length'] = train[column].apply(len)    #Hotel_Name_length: ホテル名の文字数\n",
        "    test[f'{column}_length'] = test[column].apply(len)      #Hotel_Name_length: ホテル名の文字数\n",
        "\n",
        "    train[f'{column}_frequency'] = train[column].map(train[column].value_counts())  #Hotel_Name_frequency: データセット全体におけるそのホテル名の出現頻度\n",
        "    test[f'{column}_frequency'] = test[column].map(train[column].value_counts())    #Hotel_Name_frequency: データセット全体におけるそのホテル名の出現頻度\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# 4．ホテル名の処理(実行)\n",
        "hotel_name_column = 'Hotel_Name'\n",
        "train, test = preprocess_hotel_names(train, test, hotel_name_column)\n",
        "\n",
        "\n",
        "# 5. 緯度・経度の組み合わせ(定義)\n",
        "#機械学習モデルがホテルの位置情報をより効果的に利用できるようにするために設計\n",
        "#train、testに、lat_lng と lat_lng_encoded という2つの新しいカラムを追加する\n",
        "\"\"\"\n",
        "1.緯度経度の結合:\n",
        "lat カラム（緯度）と lng カラム（経度）の値を文字列に変換し、\"_\" で連結して新しい lat_lng カラムを作成します。\n",
        "例えば、緯度が35.6895、経度が139.6917の場合、lat_lng カラムの値は \"35.6895_139.6917\" となります。\n",
        "これにより、緯度と経度を組み合わせた単一の特徴量が生成されます。\n",
        "2.ラベルエンコーディング:\n",
        "LabelEncoder を使用して、lat_lng カラムの値を数値に変換します。\n",
        "LabelEncoder は、カテゴリカルデータを数値に変換する際に使用される手法です。\n",
        "fit_transform メソッドを使用して、train データフレームの lat_lng カラムに含まれるユニークな値にそれぞれ数値を割り当てます。\n",
        "transform メソッドを使用して、test データフレームの lat_lng カラムの値を、train データフレームで割り当てられた数値に変換します。\n",
        "これにより、lat_lng_encoded という新しいカラムが作成され、緯度経度の組み合わせが数値で表現されます。\n",
        "\"\"\"\n",
        "def preprocess_lat_lng(train, test, lat_column, lng_column):\n",
        "    # K-meansクラスタリングの代わりに、簡単な組み合わせ特徴量を作成\n",
        "    train['lat_lng'] = train[lat_column].astype(str) + '_' + train[lng_column].astype(str)\n",
        "    test['lat_lng'] = test[lat_column].astype(str) + '_' + test[lng_column].astype(str)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    train['lat_lng_encoded'] = encoder.fit_transform(train['lat_lng'])\n",
        "    test['lat_lng_encoded'] = encoder.transform(test['lat_lng'])\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# 5．緯度・経度の組み合わせ(実行)\n",
        "lat_column = 'lat'\n",
        "lng_column = 'lng'\n",
        "train, test = preprocess_lat_lng(train, test, lat_column, lng_column)\n",
        "\n",
        "\n",
        "#11月25日特徴量追加\n",
        "# レビューの時間帯（朝、昼、夜）を特徴量として追加\n",
        "def add_time_features(df, date_column):\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    df['review_hour'] = df[date_column].dt.hour\n",
        "    df['review_time_of_day'] = df['review_hour'].apply(lambda x: 'morning' if 5 <= x < 12 else ('afternoon' if 12 <= x < 17 else 'evening'))\n",
        "    return df\n",
        "# 実行\n",
        "date_column = 'Review_Date'\n",
        "train = add_time_features(train, date_column)\n",
        "test = add_time_features(test, date_column)\n",
        "\n",
        "\n",
        "\n",
        "# テキストの読みやすさ指標を追加\n",
        "from textstat import textstat\n",
        "def add_readability_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_flesch_reading_ease'] = df[col].apply(lambda x: textstat.flesch_reading_ease(x) if pd.notnull(x) else 0)\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_readability_features(train, review_columns)\n",
        "test = add_readability_features(test, review_columns)\n",
        "\n",
        "\n",
        "\n",
        "# KMeansクラスタリングを使用してクラスタIDを特徴量として追加\n",
        "from sklearn.cluster import KMeans\n",
        "def add_clustering_features(df, columns, n_clusters=5):\n",
        "    for col in columns:\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        df[f'{col}_cluster'] = kmeans.fit_predict(df[col].values.reshape(-1, 1))\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_clustering_features(train, review_columns)\n",
        "test = add_clustering_features(test, review_columns)\n",
        "\n",
        "\n",
        "\n",
        "# SpaCyを使用してエンティティを抽出し、特徴量として追加\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def add_entity_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_entities'] = df[col].apply(lambda x: ' '.join([ent.label_ for ent in nlp(x).ents]) if pd.notnull(x) else '')\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_entity_features(train, review_columns)\n",
        "test = add_entity_features(test, review_columns)\n",
        "\n",
        "\n",
        "# 既存の特徴量の積や商などの相互作用項を生成\n",
        "def add_interaction_features(df, columns):\n",
        "    for i in range(len(columns)):\n",
        "        for j in range(i + 1, len(columns)):\n",
        "            col1 = columns[i]\n",
        "            col2 = columns[j]\n",
        "            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]\n",
        "            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)  # ゼロ除算を防ぐために小さな値を追加\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "numeric_columns = ['review_hour', 'review_weekday', 'review_month', 'review_quarter', 'review_season']\n",
        "train = add_interaction_features(train, numeric_columns)\n",
        "test = add_interaction_features(test, numeric_columns)\n",
        "\n",
        "\n",
        "#一番古いコーディング部分\n",
        "def preprocess_data(df):\n",
        "\n",
        "    # レビューの文字数を計算する\n",
        "    df['Positive_Review_Length'] = df['Positive_Review'].apply(len)\n",
        "    df['Negative_Review_Length'] = df['Negative_Review'].apply(len)\n",
        "\n",
        "    # レビューのポジティブ・ネガティブ比率\n",
        "    df['Review_Word_Ratio'] = df['Positive_Review_Length'] / (df['Negative_Review_Length'] + 1)\n",
        "\n",
        "    # ポジティブレビューの単語数を計算\n",
        "    df['Positive_Review_Word_Count'] = df['Positive_Review'].apply(lambda x: len(x.split()))\n",
        "    # ネガティブレビューの単語数を計算\n",
        "    df['Negative_Review_Word_Count'] = df['Negative_Review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # VADERを使ったセンチメント分析\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    df['Positive_Review_Sentiment'] = df['Positive_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "    df['Negative_Review_Sentiment'] = df['Negative_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "\n",
        "    # 過去のレビュー数と平均スコア\n",
        "    df['Reviews_Per_Hotel'] = df.groupby('Hotel_Name')['Total_Number_of_Reviews'].transform('sum')\n",
        "    df['Average_Score_Per_Hotel'] = df.groupby('Hotel_Name')['Average_Score'].transform('mean')\n",
        "\n",
        "    # ホテルのレビュー数の変化\n",
        "    df['Review_Trend'] = df.groupby('Hotel_Name')['Total_Number_of_Reviews'].transform(lambda x: x.diff().fillna(0))\n",
        "    df['Average_Score_Trend'] = df.groupby('Hotel_Name')['Average_Score'].transform(lambda x: x.diff().fillna(0))\n",
        "\n",
        "    # レビュアーのアクティブ度\n",
        "    df['Reviewer_Activity'] = df['Total_Number_of_Reviews_Reviewer_Has_Given'] / df['days_since_review'].apply(lambda x: int(x.split()[0]))\n",
        "\n",
        "    # 月ごとの宿泊者満足度\n",
        "    if 'Reviewer_Score' in df.columns:\n",
        "        df['Monthly_Avg_Score'] = df.groupby('review_month')['Reviewer_Score'].transform('mean')\n",
        "\n",
        "    # 否定的・肯定的なレビューの有無\n",
        "    df['Has_Negative_Review'] = df['Negative_Review'].apply(lambda x: 1 if x.strip() else 0)\n",
        "    df['Has_Positive_Review'] = df['Positive_Review'].apply(lambda x: 1 if x.strip() else 0)\n",
        "\n",
        "    # レビュアーの詳細情報解析\n",
        "    df['Trip_Type'] = df['Tags'].apply(lambda x: 1 if 'Leisure trip' in x else 0)\n",
        "    df['With_Family'] = df['Tags'].apply(lambda x: 1 if 'Family with young children' in x or 'Family with older children' in x else 0)\n",
        "    df['With_Partner'] = df['Tags'].apply(lambda x: 1 if 'Couple' in x else 0)\n",
        "    df['Solo_Traveler'] = df['Tags'].apply(lambda x: 1 if 'Solo traveler' in x else 0)\n",
        "\n",
        "    return df\n",
        "\n",
        "#一番古いコーディング部分の実行\n",
        "train = preprocess_data(train)\n",
        "test = preprocess_data(test)\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#時間特徴量の生成\n",
        "# レビューの時間帯（朝、昼、夜）を特徴量として追加\n",
        "def add_time_features(df, date_column):\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    df['review_hour'] = df[date_column].dt.hour\n",
        "    df['review_time_of_day'] = df['review_hour'].apply(lambda x: 'morning' if 5 <= x < 12 else ('afternoon' if 12 <= x < 17 else 'evening'))\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "date_column = 'Review_Date'\n",
        "train = add_time_features(train, date_column)\n",
        "test = add_time_features(test, date_column)"
      ],
      "metadata": {
        "id": "YJ-EKWfDybs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストの読みやすさ指標\n",
        "from textstat import textstat\n",
        "\n",
        "# テキストの読みやすさ指標を追加\n",
        "def add_readability_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_flesch_reading_ease'] = df[col].apply(lambda x: textstat.flesch_reading_ease(x) if pd.notnull(x) else 0)\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_readability_features(train, review_columns)\n",
        "test = add_readability_features(test, review_columns)"
      ],
      "metadata": {
        "id": "1ZgKMOfTyhfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#クラスタリングによる特徴量\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# KMeansクラスタリングを使用してクラスタIDを特徴量として追加\n",
        "def add_clustering_features(df, columns, n_clusters=5):\n",
        "    for col in columns:\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        df[f'{col}_cluster'] = kmeans.fit_predict(df[col].values.reshape(-1, 1))\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_clustering_features(train, review_columns)\n",
        "test = add_clustering_features(test, review_columns)"
      ],
      "metadata": {
        "id": "13HRMRTpyBNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#エンティティ認識\n",
        "import spacy\n",
        "\n",
        "# SpaCyを使用してエンティティを抽出し、特徴量として追加\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def add_entity_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_entities'] = df[col].apply(lambda x: ' '.join([ent.label_ for ent in nlp(x).ents]) if pd.notnull(x) else '')\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_entity_features(train, review_columns)\n",
        "test = add_entity_features(test, review_columns)"
      ],
      "metadata": {
        "id": "bj4vEt_DyFHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 既存の特徴量の積や商などの相互作用項を生成\n",
        "def add_interaction_features(df, columns):\n",
        "    for i in range(len(columns)):\n",
        "        for j in range(i + 1, len(columns)):\n",
        "            col1 = columns[i]\n",
        "            col2 = columns[j]\n",
        "            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]\n",
        "            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)  # ゼロ除算を防ぐために小さな値を追加\n",
        "    return df\n",
        "\n",
        "# 実行\n",
        "numeric_columns = ['review_hour', 'review_weekday', 'review_month', 'review_quarter', 'review_season']\n",
        "train = add_interaction_features(train, numeric_columns)\n",
        "test = add_interaction_features(test, numeric_columns)"
      ],
      "metadata": {
        "id": "e2n-yW6eyQfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. タグの埋め込み表現\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def add_tag_embeddings(df, tag_column, vector_size=50):\n",
        "    tags = df[tag_column].dropna().apply(lambda x: x.split(',')).tolist()\n",
        "    model = Word2Vec(tags, vector_size=vector_size, window=5, min_count=1, sg=1)\n",
        "    def get_tag_vector(tags):\n",
        "        tag_vecs = [model.wv[tag] for tag in tags if tag in model.wv]\n",
        "        if tag_vecs:\n",
        "            return np.mean(tag_vecs, axis=0)\n",
        "        else:\n",
        "            return np.zeros(vector_size)\n",
        "    tag_vectors = df[tag_column].apply(lambda x: get_tag_vector(x.split(',')) if pd.notnull(x) else np.zeros(vector_size))\n",
        "    tag_vectors_df = pd.DataFrame(tag_vectors.tolist(), index=df.index)\n",
        "    return pd.concat([df, tag_vectors_df], axis=1)\n",
        "\n",
        "train = add_tag_embeddings(train, 'Tags')\n",
        "test = add_tag_embeddings(test, 'Tags')"
      ],
      "metadata": {
        "id": "1qDa5Sn_XNz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#タグのクラスタリング\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def add_tag_clusters(df, tag_column, n_clusters=5):\n",
        "    vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','))\n",
        "    tag_matrix = vectorizer.fit_transform(df[tag_column].fillna(''))\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(tag_matrix)\n",
        "    df[tag_column + '_cluster'] = kmeans.labels_\n",
        "    return df\n",
        "\n",
        "train = add_tag_clusters(train, 'Tags')\n",
        "test = add_tag_clusters(test, 'Tags')"
      ],
      "metadata": {
        "id": "tmfbqL3Bxp49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYLWwxfjReWs",
        "outputId": "6206d27e-cf1d-4dc4-9101-6551d0d6d8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283366, 867)\n",
            "(231845, 865)\n"
          ]
        }
      ],
      "source": [
        "#6まで全体のバックアップ取得\n",
        "train_bkup6 = train.copy()\n",
        "test_bkup6 = test.copy()\n",
        "\n",
        "print(train_bkup6.shape)\n",
        "print(test_bkup6.shape)\n",
        "\n",
        "#(283366, 327)\n",
        "#(231845, 325)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "r4ddnBwQZ-jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6446f24-3aa0-4cd4-a0e0-53478b233cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283366, 867)\n",
            "(231845, 865)\n"
          ]
        }
      ],
      "source": [
        "#バックアップから戻す\n",
        "train = train_bkup6.copy()\n",
        "test = test_bkup6.copy()\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XScmbuIHdpD",
        "outputId": "1380f016-6add-4462-94ff-42323b15602e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean RMSE (LightGBM): 1.0168\n",
            "Mean RMSE (XGBoost): 1.0174\n",
            "Mean RMSE (CatBoost): 1.0320\n",
            "End: 2024-11-25 14:55:58.512067\n",
            "ProcessTime: 0:56:20.228152\n"
          ]
        }
      ],
      "source": [
        "\"\"\"#アンサンブルコード書き直し　11月25日\n",
        "#ランダムフォレスト除外\n",
        "#3つのモデルのハイパーパラメータ変更\n",
        "\"\"\"\n",
        "from datetime import datetime\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "# 必要なモジュールのインポートを追加→結局使わない\n",
        "#from xgboost.callback import EarlyStopping\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "# 訓練用データセットの数値型以外の列を削除する\n",
        "train = train.select_dtypes(include=['int64', 'float64', 'int32'])\n",
        "\n",
        "# 推論用データセットにもレビュースコア以外の同様の列を残す\n",
        "test = test[[col for col in train.columns if col in test.columns]]\n",
        "\n",
        "# 訓練用データセットからターゲットを分離する\n",
        "X = train.drop('Reviewer_Score', axis=1)\n",
        "y = train['Reviewer_Score']\n",
        "\n",
        "# テストデータに存在しない列を追加して0で埋める\n",
        "missing_cols = set(X.columns) - set(test.columns)\n",
        "for col in missing_cols:\n",
        "    test[col] = 0\n",
        "\n",
        "\n",
        "# 列の順番を訓練データと同じにする\n",
        "test = test[X.columns]\n",
        "\n",
        "# 無限大の値を置換\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# 欠損値を平均値で補完 (他の方法でも補完可能)\n",
        "X = X.fillna(X.mean())            #平均値で埋める\n",
        "test = test.fillna(test.mean())\n",
        "# 例：X_train = X_train.dropna()  # NaN値を含む行を削除\n",
        "\n",
        "# float64に型変換\n",
        "X = X.astype(np.float64)\n",
        "test = test.astype(np.float64)\n",
        "\n",
        "\n",
        "# KFoldによる分割設定\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 結果を保存するリスト\n",
        "rmses = []\n",
        "test_preds_lgb = np.zeros(test.shape[0])\n",
        "test_preds_rf = np.zeros(test.shape[0])\n",
        "test_preds_xgb = np.zeros(test.shape[0])\n",
        "test_preds_cat = np.zeros(test.shape[0])\n",
        "\n",
        "# 各モデルの最適なハイパーパラメータの設定\n",
        "lgb_params = {\n",
        "    'learning_rate': 0.0992812083091482,   #0.05から変更\n",
        "    'min_child_samples': 61,    #\n",
        "    'n_estimators': 1000,   #500から変更\n",
        "    'num_leaves': 250,\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "#Optunaで算出したパラメータ\n",
        "#Best parameters: {'learning_rate': 0.0992812083091482, 'num_leaves': 250, 'min_child_samples': 61}\n",
        "#Best RMSE: 1.012224322083124\n",
        "\"\"\"\n",
        "rf_params = {\n",
        "    'n_estimators': 25, #ランダムフォレストを構成する決定木の数,100〜200 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'random_state': 42, #乱数シード\n",
        "    'max_depth': 10,    #各決定木の最大深さ None（制限なし）から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'min_samples_split': 2, #ノードを分割するために必要な最小サンプル数 2〜10 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'min_samples_leaf': 1,  #葉ノードに存在する最小サンプル数 1〜5 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    #'max_features': 'auto',    #各決定木でノードを分割する際に考慮する特徴量の最大数 'auto'（特徴量の数の平方根）、'sqrt'、'log2' など\n",
        "    'n_jobs': -1    #並列処理に使用するコア数  -1 を指定すると、すべてのコアを使用\n",
        "}\n",
        "\"\"\"\n",
        "xgb_params = {\n",
        "    'learning_rate': 0.1,  #デフォルトは0.3　一般的に、0.01〜0.1程度の値が使用される。\n",
        "    'n_estimators': 1000,    #ブースター（決定木）の数\n",
        "    'objective': 'reg:squarederror',    #reg:squarederror（回帰）\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "cat_params = {\n",
        "    'iterations': 500,      #学習の反復回数 (決定木の数)\n",
        "    'learning_rate': 0.1,  #学習率\n",
        "    'depth': 6,             #決定木の最大深度\n",
        "    'loss_function': 'RMSE',#損失関数\n",
        "    'random_seed': 42,      #乱数シード\n",
        "    'verbose': 0            #学習過程の出力レベル　0表示なし　1表示あり\n",
        "}\n",
        "\n",
        "# 各foldでの訓練と評価\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold+1} Start:{datetime.now()}\")\n",
        "\n",
        "    # 訓練用データと検証用データに分割\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "    # ランダムフォレストモデルの訓練\n",
        "    #rf_model = RandomForestRegressor(**rf_params)\n",
        "    #rf_model.fit(X_train, y_train)\n",
        "    #print(f\"Fold {fold+1} ランダムフォレスト time:{datetime.now()}\")\n",
        "\n",
        "    # LightGBMモデルの訓練\n",
        "    lgb_model = lgb.train(\n",
        "        lgb_params,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "    print(f\"Fold {fold+1} LightGBM time:{datetime.now()}\")\n",
        "\n",
        "\n",
        "    # XGBoostモデルの訓練\n",
        "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "    early_stop = EarlyStopping(rounds=50) # EarlyStoppingコールバックを作成\n",
        "    #xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], callbacks=[early_stop], verbose=False) # callbacks引数に追加\n",
        "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
        "    print(f\"Fold {fold+1} XGBoost time:{datetime.now()}\")\n",
        "\n",
        "    # CatBoostモデルの訓練\n",
        "    cat_model = CatBoostRegressor(**cat_params)\n",
        "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=50, verbose=False)\n",
        "    print(f\"Fold {fold+1} CatBoost time:{datetime.now()}\")\n",
        "\n",
        "    # 検証用データセットに対する予測\n",
        "    y_pred_lgb = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "    #y_pred_rf = rf_model.predict(X_valid)\n",
        "    y_pred_xgb = xgb_model.predict(X_valid)\n",
        "    y_pred_cat = cat_model.predict(X_valid)\n",
        "\n",
        "    # モデルの性能をRMSEで評価\n",
        "    rmse_lgb = mean_squared_error(y_valid, y_pred_lgb, squared=False)\n",
        "    #rmse_rf = mean_squared_error(y_valid, y_pred_rf, squared=False)\n",
        "    rmse_xgb = mean_squared_error(y_valid, y_pred_xgb, squared=False)\n",
        "    rmse_cat = mean_squared_error(y_valid, y_pred_cat, squared=False)\n",
        "    print(f\"Fold {fold+1} RMSE (LightGBM): {rmse_lgb:.4f}\")\n",
        "    #print(f\"Fold {fold+1} RMSE (RandomForest): {rmse_rf:.4f}\")\n",
        "    print(f\"Fold {fold+1} RMSE (XGBoost): {rmse_xgb:.4f}\")\n",
        "    print(f\"Fold {fold+1} RMSE (CatBoost): {rmse_cat:.4f}\")\n",
        "\n",
        "    # 各foldの結果を保存\n",
        "    #rmses.append((rmse_lgb, rmse_rf, rmse_xgb, rmse_cat))\n",
        "    rmses.append((rmse_lgb, rmse_xgb, rmse_cat))\n",
        "\n",
        "    # テストデータに対する予測を平均\n",
        "    test_preds_lgb += lgb_model.predict(test, num_iteration=lgb_model.best_iteration) / kf.n_splits\n",
        "    #test_preds_rf += rf_model.predict(test) / kf.n_splits\n",
        "    test_preds_xgb += xgb_model.predict(test) / kf.n_splits\n",
        "    test_preds_cat += cat_model.predict(test) / kf.n_splits\n",
        "\n",
        "# 全体の平均RMSE\n",
        "mean_rmse_lgb = sum([rmse[0] for rmse in rmses]) / len(rmses)\n",
        "#mean_rmse_rf = sum([rmse[1] for rmse in rmses]) / len(rmses)\n",
        "mean_rmse_xgb = sum([rmse[2] for rmse in rmses]) / len(rmses)\n",
        "mean_rmse_cat = sum([rmse[3] for rmse in rmses]) / len(rmses)　#11/25 理由不明、ここで落ちた　IndexError: tuple index out of range\n",
        "\"\"\"\n",
        "print(f\"Mean RMSE (LightGBM): {mean_rmse_lgb:.4f}\")\n",
        "#print(f\"Mean RMSE (RandomForest): {mean_rmse_rf:.4f}\")\n",
        "print(f\"Mean RMSE (XGBoost): {mean_rmse_xgb:.4f}\")\n",
        "print(f\"Mean RMSE (CatBoost): {mean_rmse_cat:.4f}\")\n",
        "\n",
        "# アンサンブル予測の平均\n",
        "#final_test_preds = (test_preds_lgb + test_preds_rf + test_preds_xgb + test_preds_cat) / 4\n",
        "final_test_preds = (test_preds_lgb + test_preds_xgb + test_preds_cat) / 3\n",
        "\n",
        "# 予測結果を保存する\n",
        "submit = pd.read_csv('/content/drive/MyDrive/data/sample_submission.csv', header=None)\n",
        "submit[1] = final_test_preds\n",
        "submit.to_csv('/content/drive/MyDrive/data/submit_ensemble.csv', header=None, index=False)\n",
        "\n",
        "submit.head()\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"コピー用\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")"
      ],
      "metadata": {
        "id": "y6m2wTB9lhHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "#learning_rate, num_leaves, max_depthはモデルの性能に大きく影響するため、優先的にチューニングすることをお勧めします。\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの範囲を指定\n",
        "    param = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    # LightGBMモデルの学習\n",
        "    lgb_model = lgb.train(\n",
        "        param,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "\n",
        "    # 予測とRMSEの計算\n",
        "    y_pred = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse  # 最小化したい指標を返す\n",
        "\n",
        "study = optuna.create_study(direction='minimize')  # 最小化したい場合は 'minimize'\n",
        "study.optimize(objective, n_trials=100)  # 試行回数\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxM7toEDI56K",
        "outputId": "9ae01694-320d-4e5b-8c07-4e7ed2a9ece7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:12:01,443] A new study created in memory with name: no-name-75506969-ef45-4bdc-89c5-2bd4af00e89a\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.13216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:12:37,887] Trial 0 finished with value: 1.064029094718614 and parameters: {'learning_rate': 0.032854689317553296, 'num_leaves': 69, 'min_child_samples': 14}. Best is trial 0 with value: 1.064029094718614.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.14361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:13:42,175] Trial 1 finished with value: 1.0693980160917085 and parameters: {'learning_rate': 0.025887384126961625, 'num_leaves': 141, 'min_child_samples': 16}. Best is trial 0 with value: 1.064029094718614.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.11799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:14:55,909] Trial 2 finished with value: 1.4553308792067672 and parameters: {'learning_rate': 0.0027366493764016883, 'num_leaves': 117, 'min_child_samples': 95}. Best is trial 0 with value: 1.064029094718614.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.86951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:16:24,452] Trial 3 finished with value: 1.3673013768040319 and parameters: {'learning_rate': 0.004402762447775082, 'num_leaves': 209, 'min_child_samples': 80}. Best is trial 0 with value: 1.064029094718614.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.95973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:17:22,756] Trial 4 finished with value: 1.3999023696928432 and parameters: {'learning_rate': 0.0037382098189221273, 'num_leaves': 171, 'min_child_samples': 70}. Best is trial 0 with value: 1.064029094718614.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:18:21,444] Trial 5 finished with value: 1.016252974940816 and parameters: {'learning_rate': 0.07221446042689698, 'num_leaves': 226, 'min_child_samples': 96}. Best is trial 5 with value: 1.016252974940816.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.9216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:18:56,184] Trial 6 finished with value: 1.3862167133790821 and parameters: {'learning_rate': 0.00436401006385197, 'num_leaves': 56, 'min_child_samples': 23}. Best is trial 5 with value: 1.016252974940816.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.05805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:20:09,730] Trial 7 finished with value: 1.434591921554168 and parameters: {'learning_rate': 0.002976974995463791, 'num_leaves': 273, 'min_child_samples': 8}. Best is trial 5 with value: 1.016252974940816.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.93227\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:20:59,128] Trial 8 finished with value: 1.3900617838584932 and parameters: {'learning_rate': 0.004041153863291032, 'num_leaves': 116, 'min_child_samples': 63}. Best is trial 5 with value: 1.016252974940816.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.33237\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:21:49,487] Trial 9 finished with value: 1.5272090614190057 and parameters: {'learning_rate': 0.001522684036657684, 'num_leaves': 133, 'min_child_samples': 9}. Best is trial 5 with value: 1.016252974940816.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:23:23,829] Trial 10 finished with value: 1.0147045134195116 and parameters: {'learning_rate': 0.08889626921971382, 'num_leaves': 290, 'min_child_samples': 38}. Best is trial 10 with value: 1.0147045134195116.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02622\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:24:36,048] Trial 11 finished with value: 1.0130270400040866 and parameters: {'learning_rate': 0.09606566302262913, 'num_leaves': 298, 'min_child_samples': 45}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03174\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:25:43,988] Trial 12 finished with value: 1.015748019885015 and parameters: {'learning_rate': 0.08474221593434768, 'num_leaves': 292, 'min_child_samples': 40}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.12973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:26:52,949] Trial 13 finished with value: 1.0628858395107668 and parameters: {'learning_rate': 0.02508214372522857, 'num_leaves': 253, 'min_child_samples': 41}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.31901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:28:10,428] Trial 14 finished with value: 1.1484827522269523 and parameters: {'learning_rate': 0.012628086599098559, 'num_leaves': 300, 'min_child_samples': 37}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.05692\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:29:12,525] Trial 15 finished with value: 1.0280664884563286 and parameters: {'learning_rate': 0.04659889969374741, 'num_leaves': 241, 'min_child_samples': 53}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.29735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:30:10,530] Trial 16 finished with value: 1.139011873208804 and parameters: {'learning_rate': 0.014015740489131519, 'num_leaves': 189, 'min_child_samples': 31}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's l2: 1.03029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:31:11,077] Trial 17 finished with value: 1.0150321632144361 and parameters: {'learning_rate': 0.0953919300594343, 'num_leaves': 262, 'min_child_samples': 54}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.05225\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:32:10,275] Trial 18 finished with value: 1.0257910635766667 and parameters: {'learning_rate': 0.05032028527751928, 'num_leaves': 210, 'min_child_samples': 27}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.54865\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:33:24,033] Trial 19 finished with value: 1.244446915982135 and parameters: {'learning_rate': 0.007783124971344095, 'num_leaves': 280, 'min_child_samples': 45}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.12822\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:33:47,946] Trial 20 finished with value: 1.0621786938002753 and parameters: {'learning_rate': 0.052605883551681, 'num_leaves': 22, 'min_child_samples': 60}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:34:51,085] Trial 21 finished with value: 1.0131218311413512 and parameters: {'learning_rate': 0.09772467055697683, 'num_leaves': 259, 'min_child_samples': 51}. Best is trial 11 with value: 1.0130270400040866.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02602\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:35:50,523] Trial 22 finished with value: 1.0129261790343862 and parameters: {'learning_rate': 0.09801746962815755, 'num_leaves': 252, 'min_child_samples': 48}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.07802\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:36:55,577] Trial 23 finished with value: 1.0382790619161508 and parameters: {'learning_rate': 0.036693457441823195, 'num_leaves': 244, 'min_child_samples': 76}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04202\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:37:56,354] Trial 24 finished with value: 1.020793224044228 and parameters: {'learning_rate': 0.05990763387383375, 'num_leaves': 227, 'min_child_samples': 48}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.1767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:39:03,115] Trial 25 finished with value: 1.0847592587189643 and parameters: {'learning_rate': 0.02008935146831569, 'num_leaves': 268, 'min_child_samples': 62}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03595\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:39:58,624] Trial 26 finished with value: 1.017816940684662 and parameters: {'learning_rate': 0.06902428958702933, 'num_leaves': 202, 'min_child_samples': 50}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:40:51,024] Trial 27 finished with value: 1.013426406427234 and parameters: {'learning_rate': 0.09716565311860789, 'num_leaves': 177, 'min_child_samples': 69}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.08387\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:41:52,918] Trial 28 finished with value: 1.0410905401344275 and parameters: {'learning_rate': 0.03551376476317772, 'num_leaves': 237, 'min_child_samples': 34}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.06033\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:42:59,524] Trial 29 finished with value: 1.029722205587785 and parameters: {'learning_rate': 0.044618134722284986, 'num_leaves': 264, 'min_child_samples': 21}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.58982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:44:13,633] Trial 30 finished with value: 1.2608796763673995 and parameters: {'learning_rate': 0.007189265670164644, 'num_leaves': 300, 'min_child_samples': 57}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:45:12,416] Trial 31 finished with value: 1.013889418456129 and parameters: {'learning_rate': 0.09442949511002705, 'num_leaves': 181, 'min_child_samples': 68}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.05353\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:45:54,483] Trial 32 finished with value: 1.0264158010984261 and parameters: {'learning_rate': 0.06816160602713207, 'num_leaves': 84, 'min_child_samples': 81}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.13726\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:46:47,364] Trial 33 finished with value: 1.0664246026124675 and parameters: {'learning_rate': 0.02640381135742411, 'num_leaves': 151, 'min_child_samples': 88}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:47:50,854] Trial 34 finished with value: 1.017723169546828 and parameters: {'learning_rate': 0.06753961370601465, 'num_leaves': 227, 'min_child_samples': 70}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.3977\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:49:05,309] Trial 35 finished with value: 1.5484515859326042 and parameters: {'learning_rate': 0.0011732675409033139, 'num_leaves': 276, 'min_child_samples': 46}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02699\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:49:59,768] Trial 36 finished with value: 1.013406838374841 and parameters: {'learning_rate': 0.09760506060501244, 'num_leaves': 211, 'min_child_samples': 56}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.071\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:51:01,511] Trial 37 finished with value: 1.0348932106506947 and parameters: {'learning_rate': 0.040599895226340256, 'num_leaves': 211, 'min_child_samples': 44}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.10975\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:52:20,327] Trial 38 finished with value: 1.0534481284598674 and parameters: {'learning_rate': 0.02862417818773092, 'num_leaves': 252, 'min_child_samples': 55}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:53:16,639] Trial 39 finished with value: 1.0198807127919298 and parameters: {'learning_rate': 0.060897802413402764, 'num_leaves': 195, 'min_child_samples': 30}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.16812\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:54:17,041] Trial 40 finished with value: 1.080794787872334 and parameters: {'learning_rate': 0.02138453499824644, 'num_leaves': 217, 'min_child_samples': 64}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02981\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:55:08,874] Trial 41 finished with value: 1.0147944568914946 and parameters: {'learning_rate': 0.07965664122016837, 'num_leaves': 172, 'min_child_samples': 74}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:56:01,748] Trial 42 finished with value: 1.0148934476468607 and parameters: {'learning_rate': 0.09532845828364131, 'num_leaves': 168, 'min_child_samples': 58}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02674\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:57:06,324] Trial 43 finished with value: 1.0132823163683577 and parameters: {'learning_rate': 0.09897122605805841, 'num_leaves': 281, 'min_child_samples': 50}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:58:13,265] Trial 44 finished with value: 1.0150709863308054 and parameters: {'learning_rate': 0.07821559338305603, 'num_leaves': 282, 'min_child_samples': 52}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04509\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 12:59:38,889] Trial 45 finished with value: 1.022298539054563 and parameters: {'learning_rate': 0.05405034597423415, 'num_leaves': 255, 'min_child_samples': 43}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.0278\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:00:43,856] Trial 46 finished with value: 1.0138038236347895 and parameters: {'learning_rate': 0.07727940085086343, 'num_leaves': 282, 'min_child_samples': 48}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03828\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:01:45,030] Trial 47 finished with value: 1.0189604448358989 and parameters: {'learning_rate': 0.0630204264568328, 'num_leaves': 238, 'min_child_samples': 36}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02891\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:03:02,462] Trial 48 finished with value: 1.0143539354696867 and parameters: {'learning_rate': 0.07788589455711048, 'num_leaves': 288, 'min_child_samples': 65}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.13088\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:04:14,016] Trial 49 finished with value: 1.4597536106938982 and parameters: {'learning_rate': 0.00254293300623209, 'num_leaves': 269, 'min_child_samples': 40}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.06572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:05:18,218] Trial 50 finished with value: 1.0323394635885217 and parameters: {'learning_rate': 0.04173701318639185, 'num_leaves': 253, 'min_child_samples': 53}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:06:07,595] Trial 51 finished with value: 1.014026092224091 and parameters: {'learning_rate': 0.09512368717368945, 'num_leaves': 153, 'min_child_samples': 59}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02606\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:07:04,210] Trial 52 finished with value: 1.0129445225036933 and parameters: {'learning_rate': 0.09976035679152448, 'num_leaves': 224, 'min_child_samples': 50}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:08:03,649] Trial 53 finished with value: 1.0214616480573482 and parameters: {'learning_rate': 0.057104062607379415, 'num_leaves': 220, 'min_child_samples': 51}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:09:02,668] Trial 54 finished with value: 1.0149611231116635 and parameters: {'learning_rate': 0.0825356319135842, 'num_leaves': 233, 'min_child_samples': 42}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04673\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:10:11,623] Trial 55 finished with value: 1.0230991946484957 and parameters: {'learning_rate': 0.0503851764639198, 'num_leaves': 294, 'min_child_samples': 46}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:11:11,701] Trial 56 finished with value: 1.0150716133125612 and parameters: {'learning_rate': 0.098556562130538, 'num_leaves': 246, 'min_child_samples': 49}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03351\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:12:25,242] Trial 57 finished with value: 1.0166173000695806 and parameters: {'learning_rate': 0.07173467943114228, 'num_leaves': 262, 'min_child_samples': 55}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.11251\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:13:11,048] Trial 58 finished with value: 1.0547578932396178 and parameters: {'learning_rate': 0.032406305988348566, 'num_leaves': 123, 'min_child_samples': 38}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02759\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:14:13,141] Trial 59 finished with value: 1.0137026947903194 and parameters: {'learning_rate': 0.08222551264058599, 'num_leaves': 273, 'min_child_samples': 100}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:15:09,095] Trial 60 finished with value: 1.0207033809529495 and parameters: {'learning_rate': 0.05933967806418416, 'num_leaves': 202, 'min_child_samples': 33}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:16:02,295] Trial 61 finished with value: 1.0143092432726422 and parameters: {'learning_rate': 0.09804790049271311, 'num_leaves': 191, 'min_child_samples': 62}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:17:04,027] Trial 62 finished with value: 1.015833262140297 and parameters: {'learning_rate': 0.06958741699195829, 'num_leaves': 258, 'min_child_samples': 69}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03102\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:18:01,665] Trial 63 finished with value: 1.0153894860626989 and parameters: {'learning_rate': 0.08558141379838759, 'num_leaves': 219, 'min_child_samples': 74}. Best is trial 22 with value: 1.0129261790343862.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:19:03,559] Trial 64 finished with value: 1.0127981536873096 and parameters: {'learning_rate': 0.09888584145877595, 'num_leaves': 293, 'min_child_samples': 84}. Best is trial 64 with value: 1.0127981536873096.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.05603\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:20:06,895] Trial 65 finished with value: 1.0276315914158125 and parameters: {'learning_rate': 0.04586558629897882, 'num_leaves': 289, 'min_child_samples': 88}. Best is trial 64 with value: 1.0127981536873096.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.66515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:21:21,241] Trial 66 finished with value: 1.2904074384439637 and parameters: {'learning_rate': 0.006244708454162591, 'num_leaves': 300, 'min_child_samples': 13}. Best is trial 64 with value: 1.0127981536873096.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03286\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:22:22,299] Trial 67 finished with value: 1.016296870212053 and parameters: {'learning_rate': 0.06676927059997449, 'num_leaves': 278, 'min_child_samples': 91}. Best is trial 64 with value: 1.0127981536873096.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02521\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:23:21,368] Trial 68 finished with value: 1.012524485906643 and parameters: {'learning_rate': 0.08759024443515998, 'num_leaves': 266, 'min_child_samples': 79}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.35771\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:24:27,899] Trial 69 finished with value: 1.165208558469253 and parameters: {'learning_rate': 0.011638365608110936, 'num_leaves': 270, 'min_child_samples': 84}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:25:25,348] Trial 70 finished with value: 1.0138313050621681 and parameters: {'learning_rate': 0.08681672932165826, 'num_leaves': 247, 'min_child_samples': 94}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02591\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:26:26,241] Trial 71 finished with value: 1.0128706354747963 and parameters: {'learning_rate': 0.09949657246576254, 'num_leaves': 289, 'min_child_samples': 83}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02986\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:27:30,023] Trial 72 finished with value: 1.0148205733149223 and parameters: {'learning_rate': 0.0750224552263091, 'num_leaves': 286, 'min_child_samples': 83}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02694\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:28:32,599] Trial 73 finished with value: 1.0133817706380934 and parameters: {'learning_rate': 0.08392537436409916, 'num_leaves': 296, 'min_child_samples': 81}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04189\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:29:35,288] Trial 74 finished with value: 1.0207318125655833 and parameters: {'learning_rate': 0.05584876191712761, 'num_leaves': 264, 'min_child_samples': 88}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.23991\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:30:40,481] Trial 75 finished with value: 1.1135123250206134 and parameters: {'learning_rate': 0.015931856820010644, 'num_leaves': 278, 'min_child_samples': 77}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03738\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:31:46,128] Trial 76 finished with value: 1.0185191302645882 and parameters: {'learning_rate': 0.06356946314669316, 'num_leaves': 289, 'min_child_samples': 47}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02573\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:32:46,269] Trial 77 finished with value: 1.0127811827541646 and parameters: {'learning_rate': 0.08846286499734993, 'num_leaves': 271, 'min_child_samples': 50}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:33:48,439] Trial 78 finished with value: 1.0183897051153192 and parameters: {'learning_rate': 0.07089923800951674, 'num_leaves': 260, 'min_child_samples': 5}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:34:48,387] Trial 79 finished with value: 1.0145779991513921 and parameters: {'learning_rate': 0.0869269456362395, 'num_leaves': 271, 'min_child_samples': 40}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-25 13:35:46,339] Trial 80 finished with value: 1.0240430800435427 and parameters: {'learning_rate': 0.05166759787283785, 'num_leaves': 233, 'min_child_samples': 86}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:36:47,019] Trial 81 finished with value: 1.013052577114566 and parameters: {'learning_rate': 0.09997529466083808, 'num_leaves': 293, 'min_child_samples': 51}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:37:51,063] Trial 82 finished with value: 1.0136025500923311 and parameters: {'learning_rate': 0.0869223922917019, 'num_leaves': 295, 'min_child_samples': 78}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:38:53,160] Trial 83 finished with value: 1.0151061760001683 and parameters: {'learning_rate': 0.07665886241710677, 'num_leaves': 284, 'min_child_samples': 45}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.04021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:39:31,006] Trial 84 finished with value: 1.0199076832959848 and parameters: {'learning_rate': 0.08846664864980155, 'num_leaves': 87, 'min_child_samples': 52}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:40:33,922] Trial 85 finished with value: 1.0174939499840636 and parameters: {'learning_rate': 0.06437145722560968, 'num_leaves': 274, 'min_child_samples': 66}. Best is trial 68 with value: 1.012524485906643.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:41:32,245] Trial 86 finished with value: 1.012224322083124 and parameters: {'learning_rate': 0.0992812083091482, 'num_leaves': 250, 'min_child_samples': 61}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:42:33,673] Trial 87 finished with value: 1.0160625094786018 and parameters: {'learning_rate': 0.07376720997296289, 'num_leaves': 251, 'min_child_samples': 72}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:43:33,621] Trial 88 finished with value: 1.0130021161877414 and parameters: {'learning_rate': 0.0986362920153294, 'num_leaves': 268, 'min_child_samples': 91}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 2.2499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:44:42,140] Trial 89 finished with value: 1.499967203502066 and parameters: {'learning_rate': 0.001895650653559771, 'num_leaves': 266, 'min_child_samples': 93}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:45:40,283] Trial 90 finished with value: 1.0191338494067117 and parameters: {'learning_rate': 0.059628961661256835, 'num_leaves': 242, 'min_child_samples': 98}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:46:41,521] Trial 91 finished with value: 1.0136230140793088 and parameters: {'learning_rate': 0.09012459928549701, 'num_leaves': 294, 'min_child_samples': 91}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.0291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:47:45,219] Trial 92 finished with value: 1.014445552172005 and parameters: {'learning_rate': 0.07639350742089775, 'num_leaves': 284, 'min_child_samples': 86}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:48:44,475] Trial 93 finished with value: 1.0134926615483864 and parameters: {'learning_rate': 0.09857578408342886, 'num_leaves': 256, 'min_child_samples': 57}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:49:44,730] Trial 94 finished with value: 1.0136170131750069 and parameters: {'learning_rate': 0.08906001434446531, 'num_leaves': 272, 'min_child_samples': 79}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.03042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:50:45,996] Trial 95 finished with value: 1.0150983637020172 and parameters: {'learning_rate': 0.06925468203816414, 'num_leaves': 278, 'min_child_samples': 61}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.06186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:51:12,829] Trial 96 finished with value: 1.0304647632601156 and parameters: {'learning_rate': 0.09931032420057294, 'num_leaves': 32, 'min_child_samples': 43}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:52:19,240] Trial 97 finished with value: 1.014853434016771 and parameters: {'learning_rate': 0.07909564441765826, 'num_leaves': 298, 'min_child_samples': 49}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:53:17,482] Trial 98 finished with value: 1.0148191891323946 and parameters: {'learning_rate': 0.08187328140910917, 'num_leaves': 249, 'min_child_samples': 46}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's l2: 1.02949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:54:21,012] Trial 99 finished with value: 1.0146369149828631 and parameters: {'learning_rate': 0.09137774644534372, 'num_leaves': 290, 'min_child_samples': 53}. Best is trial 86 with value: 1.012224322083124.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.0992812083091482, 'num_leaves': 250, 'min_child_samples': 61}\n",
            "Best RMSE: 1.012224322083124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.now()\n",
        "print(f\"Start xgb_model: {start_time}\")\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    xgb_model = xgb.XGBRegressor(**param)\n",
        "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
        "\n",
        "    y_pred = xgb_model.predict(X_valid)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End xgb_model: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "jymgDjuqNfqc",
        "outputId": "b8592df9-f4bb-4c86-f98b-8772c06340b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-25 13:54:21,047] A new study created in memory with name: no-name-35dc7367-51c8-4225-89fb-3b6a2cefd334\n",
            "[I 2024-11-25 13:55:34,731] Trial 0 finished with value: 1.2647392179428705 and parameters: {'learning_rate': 0.0077421589170111145, 'max_depth': 7, 'subsample': 0.6526686693574013}. Best is trial 0 with value: 1.2647392179428705.\n",
            "[I 2024-11-25 13:57:50,011] Trial 1 finished with value: 1.029428072443435 and parameters: {'learning_rate': 0.06023303269571094, 'max_depth': 10, 'subsample': 0.6195504199316122}. Best is trial 1 with value: 1.029428072443435.\n",
            "[W 2024-11-25 13:58:24,237] Trial 2 failed with parameters: {'learning_rate': 0.0392540214780853, 'max_depth': 6, 'subsample': 0.7799363079396289} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-30-bdccbfeb872a>\", line 10, in objective\n",
            "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1108, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2101, in update\n",
            "    _LIB.XGBoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-11-25 13:58:24,240] Trial 2 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bdccbfeb872a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 最適なハイパーパラメータ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-bdccbfeb872a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1109\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             _check_call(\n\u001b[0;32m-> 2101\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2102\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.now()\n",
        "print(f\"Start Cat: {start_time}\")\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    cat_model = CatBoostRegressor(**param, verbose=False)\n",
        "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
        "\n",
        "    y_pred = cat_model.predict(X_valid)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End cat: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n"
      ],
      "metadata": {
        "id": "I9r4QonPNhAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b9mCfucL1KnG",
        "outputId": "0f446c76-ff23-4296-a833-c5f6c07edaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found: {'learning_rate': 0.05, 'min_child_samples': 50, 'n_estimators': 500, 'num_leaves': 70}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ハイパーパラメータの候補を設定\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50, 70],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'min_child_samples': [20, 30, 50]\n",
        "}\n",
        "\n",
        "# LightGBMのモデルを設定\n",
        "lgb_model = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
        "\n",
        "# GridSearchCVを使用して最適なハイパーパラメータを探索\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# 最適なハイパーパラメータを表示\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
        "    }\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    model = lgb.LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    mse = mean_squared_error(y_val, preds)\n",
        "    return mse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best parameters: \", study.best_params)\n",
        "print(\"Best MSE: \", study.best_value)"
      ],
      "metadata": {
        "id": "8d-GrfcwWkZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBMのパラメータチューニングには以下の主要なパラメータがあります。これらはモデルの性能に大きな影響を与えるため、優先して調整すると良いでしょう。\n",
        "\n",
        "num_leaves: 決定木の最大葉数。大きくするとモデルの複雑さが増すが、過学習のリスクもある。\n",
        "\n",
        "learning_rate: 学習率。小さくすると学習が安定するが、計算時間が増える。\n",
        "\n",
        "n_estimators: 決定木の数。多くすると精度が上がるが、計算コストも増える。\n",
        "\n",
        "max_depth: 決定木の最大深度。深くするとモデルの複雑さが増すが、過学習のリスクもある。\n",
        "\n",
        "min_child_weight: 子ノードの最小サンプル数。小さくすると過学習しやすくなる。\n",
        "\n",
        "subsample: バギングの割合。過学習を防ぐためにデータの一部を使用する。\n",
        "\n",
        "colsample_bytree: 決定木ごとに使用する特徴量の割合。過学習を防ぐために特徴量の一部を使用する。"
      ],
      "metadata": {
        "id": "VS_xUtRzkQIz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjQ1mUbalLM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoostのパラメータチューニングには、以下の主要なパラメータがあります。これらはモデルの性能に大きな影響を与えるため、優先して調整すると良いでしょう。\n",
        "\n",
        "iterations: 学習回数。多くすると精度が上がるが、計算コストも増える。\n",
        "\n",
        "learning_rate: 学習率。小さくすると学習が安定するが、計算時間が増える。\n",
        "\n",
        "depth: 決定木の深さ。深くするとモデルの複雑さが増すが、過学習のリスクもある。\n",
        "\n",
        "l2_leaf_reg: L2正則化項。大きくすると過学習を防ぐが、精度が下がる可能性がある。\n",
        "\n",
        "bagging_temperature: バギングの温度。大きくするとデータの一部を使用する確率が高くなる。\n",
        "\n",
        "border_count: 数値特徴量をカテゴリカルに変換する際の分割数。多くすると精度が上がるが、計算コストも増える。\n",
        "\n",
        "random_strength: 決定木の分割時にランダム性を追加する強さ。過学習を防ぐために使用する。\n",
        "\n",
        "これらのパラメータを調整することで、モデルの性能を最適化することができます。Optunaなどの自動化されたチューニングツールを使用して、効率的に最適なパラメータを見つけることをお勧めします。"
      ],
      "metadata": {
        "id": "Msmq_JhJkhuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A14zrqWFlMhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoostのパラメータチューニングには、以下の主要なパラメータがあります。これらはモデルの性能に大きな影響を与えるため、優先して調整すると良いでしょう。\n",
        "\n",
        "eta (learning_rate): 学習率。小さくすると学習が安定するが、計算時間が増える。\n",
        "\n",
        "max_depth: 決定木の深さ。深くするとモデルの複雑さが増すが、過学習のリスクもある。\n",
        "\n",
        "min_child_weight: 葉の重みの最小値。値を大きくすると過学習を防ぐが、精度が下がる可能性がある。\n",
        "\n",
        "subsample: 学習データのサンプリング率。値を小さくすると過学習を防ぐが、あまり小さくしすぎるとモデルの性能が低下する。\n",
        "\n",
        "colsample_bytree: 決定木ごとの特徴量のサンプリング率。値を小さくすると過学習を防ぐが、あまり小さくしすぎるとモデルの性能が低下する。\n",
        "\n",
        "gamma: ノード分割の基準となる損失減少の最小値。値を大きくすると過学習を防ぐが、精度が下がる可能性がある。\n",
        "\n",
        "lambda (reg_lambda): L2正則化項。大きくすると過学習を防ぐが、精度が下がる可能性がある。\n",
        "\n",
        "alpha (reg_alpha): L1正則化項。大きくすると過学習を防ぐが、精度が下がる可能性がある.\n",
        "\n",
        "これらのパラメータを調整することで、モデルの性能を最適化することができます。Optunaなどの自動化されたチューニングツールを使用して、効率的に最適なパラメータを見つけることをお勧めします。"
      ],
      "metadata": {
        "id": "Sqr6bjzQlCES"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOo0ZwHDU2CZec4l0IC4f7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}