{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misayuproject/1128kigen/blob/main/try1126_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au9GMhtndzYu",
        "outputId": "3a29fcbb-143a-4201-93d7-c02303c5ff01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#ドライブの接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CRNJVXemAGg9"
      },
      "outputs": [],
      "source": [
        "#コアデータ処理\n",
        "import pandas as pd                         # データを表のように扱うライブラリ\n",
        "import numpy as np                          # 数値計算を速くするライブラリ\n",
        "from datetime import datetime               #日付と時刻を扱うための基本的なクラス\n",
        "\n",
        "# テキスト処理と感情分析\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer       #このツールは、テキストで表現されている感情的なトーン（ポジティブ、ネガティブ、ニュートラル）を判断するのに役立ちます。\n",
        "from textblob import TextBlob               # 感情分析などの機能を提供するテキスト処理ライブラリ\n",
        "\n",
        "# 特徴量エンジニアリングと前処理:\n",
        "from scipy.sparse import hstack             # スパース行列(多くのゼロを含むデータを効率的に格納する方法であるスパース行列を操作する)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDFと呼ばれる手法を使用してテキストを数値ベクトルに変換します。これは、ドキュメント内の単語の重要性を表すのに役立ちます。\n",
        "from sklearn.feature_extraction.text import CountVectorizer # テキストデータ内の単語の出現回数を単純にカウントすることによって数値ベクトルを作成\n",
        "from sklearn.decomposition import TruncatedSVD  # 次元削減に使用され、データの特徴の数を減らします。\n",
        "from sklearn.model_selection import train_test_split  # データを訓練用と検証用に分けるために使う。機械学習モデルの性能を評価するために不可欠\n",
        "from sklearn.preprocessing import StandardScaler    # 数値特徴を平均0、分散1になるようにスケーリングすることで標準化します\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder   #テゴリデータを数値形式にエンコードするために使用\n",
        "from geopy.distance import geodesic         #主要なランドマーク(ロンドン)からの距離を計算するために使用\n",
        "\n",
        "import gensim.downloader as api             # 事前学習済みモデルをダウンロードするための api をインポート\n",
        "\n",
        "from multiprocessing import Pool            #マルチプロセス\n",
        "import multiprocessing\n",
        "\n",
        "#予測モデルに関するライブラリ\n",
        "import lightgbm as lgb                      # 勾配ブースティングフレームワーク\n",
        "import xgboost as xgb                       # もう1つの強力な勾配ブースティングライブラリ\n",
        "!pip install catboost                       # もう1つの勾配ブースティングライブラリ\n",
        "from catboost import CatBoostRegressor      # CatBoostRegressor は、特にその回帰モデル（連続値の予測）を指します\n",
        "from sklearn.ensemble import RandomForestRegressor  # これは、分類タスクと回帰タスクの両方によく使用\n",
        "from sklearn.model_selection import KFold   #データをk個のフォールド（グループ）に分割し、交差検証を行うためのクラス\n",
        "\"\"\"\n",
        "動作:\n",
        "1.データセットをk個のフォールドに分割します。\n",
        "2.k回の学習と評価を繰り返します。\n",
        "    各回で、k-1個のフォールドを学習データ、残りの1個のフォールドを検証データとして使用します。\n",
        "    学習データでモデルを学習し、検証データで性能を評価します。\n",
        "3.k回の評価結果を平均して、モデルの最終的な性能を評価します。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error # 平均二乗誤差 (MSE) を計算する関数\n",
        "\"\"\"\n",
        "計算式　MSE = (1/n) * Σ(yi - ŷi)^2\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re   #正規表現モジュール re、正規表現は、テキスト内で特定のパターンを検索したり、操作したりするための強力なツールです。\n",
        "\"\"\"\n",
        "re の用途:\n",
        "パターンマッチング: テキスト内で特定のパターン (例えば、メールアドレス、電話番号、日付) を見つける。\n",
        "テキストの置換: テキスト内の特定のパターンを別のテキストに置き換える。\n",
        "テキストの抽出: テキストから特定のパターンに一致する部分を抽出する。\n",
        "データクリーニング: データセット内のテキストデータをクリーニングし、標準化する (例えば、不要な空白を削除する、大文字と小文字を統一する)。\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')  # 不要な警告を表示しない\n",
        "\"\"\"\n",
        "1.import warnings: Pythonに組み込まれているwarningsモジュールをインポートします。このモジュールは、警告メッセージを管理するための機能を提供します。警告メッセージは、エラーほど深刻ではありませんが、潜在的な問題や非推奨の機能の使用などを示すために使われます。\n",
        "2.warnings.simplefilter('ignore'): この行が実際に警告メッセージを非表示にする処理を行います。\n",
        "    warnings.simplefilter() は、警告メッセージに対するフィルターを設定する関数です。\n",
        "    'ignore' という引数を指定することで、全ての警告メッセージを無視するように設定しています。つまり、警告メッセージはコンソールやログに出力されなくなります。\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcfo6jrpJBTF"
      },
      "outputs": [],
      "source": [
        "#データ読み込みセクション　8秒ーーーーーーーーーーーーーーーー\n",
        "#予測モデルを訓練するためのデータセット\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/train.csv', index_col=0)\n",
        "# 予測モデルに推論（予測)させるデータセット\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/test.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMlnScHBtzEs",
        "outputId": "39e6298f-cd0b-45fa-f32f-63b51a0c1c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2024-11-26 10:16:38.089463\n",
            "train : (283366, 14) - \n",
            "test : (231845, 13) - \n",
            "num_cores : 8\n",
            "num_chunks : 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing column: Positive_Review\n",
            "Processing column: Negative_Review\n",
            "train : (283366, 14) - End\n",
            "test  : (231845, 13) - End\n",
            "End  : 2024-11-26 10:20:19.113235\n",
            "ProcessingTime: 0:03:41.023772\n"
          ]
        }
      ],
      "source": [
        "#テキスト処理の完全版　11月26日\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "print(f\"train : {train.shape} - \")\n",
        "print(f\"test : {test.shape} - \")\n",
        "\n",
        "#from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt')  # This line is also needed for tokenization\n",
        "nltk.download('wordnet') # This line is also needed for lemmatization\n",
        "\n",
        "# スペル修正　・・・負荷が高いためコメントアウト\n",
        "#def correct_spelling(text):\n",
        "#    return str(TextBlob(text).correct())\n",
        "\n",
        "# 形態素解析\n",
        "#　WordNetLemmatizer を使用して単語を基本形（見出し語）に還元します。lemmatizationの精度を向上させるために、まず単語の品詞を判定します。\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split()])\n",
        "\n",
        "# 補助形容詞の削除　・・・補助形容が有用かもしれないので、削除しないでおく。\n",
        "#def remove_unhelpful_words(text):\n",
        "#    unhelpful_words = ['great', 'good', 'nice', 'excellent']\n",
        "#    return ' '.join([word for word in text.split() if word not in unhelpful_words])\n",
        "\n",
        "# クリーニング関数\n",
        "def clean_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    #text = correct_spelling(text)\n",
        "    text = lemmatize_text(text)\n",
        "    #text = remove_unhelpful_words(text)\n",
        "    return text\n",
        "\n",
        "#マルチプロセスでクリーニング関数に変更\n",
        "num_cores = multiprocessing.cpu_count()  # CPUのコア数を取得\n",
        "num_chunks = num_cores * 2  # コア数の2倍をnum_chunksに設定\n",
        "print(f\"num_cores : {num_cores}\")\n",
        "print(f\"num_chunks : {num_chunks}\")\n",
        "\n",
        "def process_chunk(chunk):\n",
        "    # chunkに対してclean_text関数を適用する\n",
        "    return chunk.apply(clean_text)\n",
        "\n",
        "def preprocess_clean_parallel(train, test, columns):\n",
        "    with Pool() as pool:\n",
        "        for col in columns:\n",
        "            print(f\"Processing column: {col}\")\n",
        "            if col in train.columns:\n",
        "                train[col] = pd.concat(pool.map(process_chunk, np.array_split(train[col], num_chunks)))  # num_chunksは適切な値を設定\n",
        "            if col in test.columns:\n",
        "                test[col] = pd.concat(pool.map(process_chunk, np.array_split(test[col], num_chunks)))  # num_chunksは適切な値を設定\n",
        "    return train, test\n",
        "\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "#train, test = preprocess_clean(train, test, review_columns)\n",
        "train, test = preprocess_clean_parallel(train, test, review_columns)\n",
        "\n",
        "# 処理時間を計算\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test  : {test.shape} - End\")\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessingTime: {processing_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4SVVt0TcLoB",
        "outputId": "f2381b1f-5456-4ab9-e749-b33c65791f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(283366, 14)\n",
            "(231845, 13)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwtnrRw9vcq",
        "outputId": "0b944562-7d8e-4662-b3cd-9536f74cef32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2024-11-26 10:21:46.554253\n",
            "train : (283366, 14) - \n",
            "test : (231845, 13) - \n",
            "add_bow_features  : 2024-11-26 10:21:53.568330 - End \n",
            "train : (283366, 24) - End\n",
            "test : (231845, 23) - End\n",
            "add_ngram_features : 2024-11-26 10:22:15.125168 - End\n",
            "train : (283366, 124) - End\n",
            "test : (231845, 123) - End\n",
            "add_tfidf_features : 2024-11-26 10:22:30.300995 - End\n",
            "train : (283366, 224) - End\n",
            "test : (231845, 223) - End\n",
            "add_embedding_features : 2024-11-26 10:24:46.757920 - End\n",
            "train : (283366, 324) - End\n",
            "test : (231845, 323) - End\n",
            "add_polarity_features : 2024-11-26 10:28:27.245117 - End\n",
            "train : (283366, 326) - End\n",
            "test : (231845, 325) - End\n",
            "Positive_Review : 2024-11-26 10:28:27.245267 - End\n",
            "add_bow_features  : 2024-11-26 10:28:34.669705 - End \n",
            "train : (283366, 336) - End\n",
            "test : (231845, 335) - End\n",
            "add_ngram_features : 2024-11-26 10:28:57.975578 - End\n",
            "train : (283366, 436) - End\n",
            "test : (231845, 435) - End\n",
            "add_tfidf_features : 2024-11-26 10:29:15.177812 - End\n",
            "train : (283366, 536) - End\n",
            "test : (231845, 535) - End\n",
            "add_embedding_features : 2024-11-26 10:31:40.177105 - End\n",
            "train : (283366, 636) - End\n",
            "test : (231845, 635) - End\n",
            "add_polarity_features : 2024-11-26 10:35:15.506518 - End\n",
            "train : (283366, 638) - End\n",
            "test : (231845, 637) - End\n",
            "Negative_Review : 2024-11-26 10:35:15.506676 - End\n",
            "preprocess_reviews2 : 2024-11-26 10:35:40.544065 - End\n",
            "train : (283366, 840) - End\n",
            "test : (231845, 839) - End\n",
            "End  : 2024-11-26 10:35:40.544388\n",
            "ProcessingTime: 0:13:53.990135\n"
          ]
        }
      ],
      "source": [
        "# Positive_ReviewとNegative_Reviewの内容をいろいろな手法で分析する.\n",
        "# BOWN,N-gram,TF-IDFの実行、埋め込み表現　・・・\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "print(f\"train : {train.shape} - \")\n",
        "print(f\"test : {test.shape} - \")\n",
        "\n",
        "def preprocess_reviews(train, test, columns):\n",
        "\n",
        "    # Bag-of-Words特徴量の追加　add_bow_features関数\n",
        "    \"\"\"\n",
        "    CountVectorizerを使用して、テキストデータを単語の出現回数に基づいた数値ベクトルに変換します。\n",
        "    stop_words='english'で英語のストップワード（一般的な単語）を削除します。\n",
        "    max_features=100で出現頻度が高い上位100単語のみを特徴量として使用します。\n",
        "    生成されたBag-of-Words特徴量は、trainとtestデータフレームに新しいカラムとして追加されます。\n",
        "    \"\"\"\n",
        "    def add_bow_features(train, test, column, max_features=10):\n",
        "        # Bag of Words特徴量の追加\n",
        "        bow = CountVectorizer(stop_words='english', max_features=10)    #max_features=50減らす\n",
        "        # 既にクリーニング済みのカラムデータをそのまま使用\n",
        "        train_bow = bow.fit_transform(train[column]).toarray()  # 変更箇所\n",
        "        test_bow = bow.transform(test[column]).toarray()       # 変更箇所\n",
        "\n",
        "        for i in range(train_bow.shape[1]):\n",
        "            train[f'{column}_bow_{i}'] = train_bow[:, i]\n",
        "            test[f'{column}_bow_{i}'] = test_bow[:, i]\n",
        "\n",
        "        return train, test\n",
        "\n",
        "\n",
        "    # テキストデータから N-gram 特徴量を抽出し、データフレームに追加する関数の定義\n",
        "    \"\"\"\n",
        "    N-gram とは、テキスト中に出現する連続した単語の組み合わせのことです。例えば、「the quick brown fox」という文から、\n",
        "        uni-gram (1-gram): the, quick, brown, fox\n",
        "        bi-gram (2-gram): the quick, quick brown, brown fox\n",
        "        tri-gram (3-gram): the quick brown, quick brown fox\n",
        "    といった N-gram を抽出できます。これらの N-gram を特徴量として使用することで、機械学習モデルはテキストデータのより深い意味を理解できるようになります。\n",
        "    CountVectorizer を使用し、uni-gram と bi-gram を抽出することで、単語の出現頻度だけでなく、単語の組み合わせも考慮した特徴量を作成している。\n",
        "    この関数は、指定されたカラム (column) のテキストデータから N-gram 特徴量を抽出し、データフレームに追加します。\n",
        "    ngram_range: N-gram の範囲を指定します。デフォルトは (1, 2) で、uni-gram と bi-gram を抽出します。\n",
        "    max_features: 追加する特徴量の上限を設定します。デフォルトは 100 で、出現頻度が高い上位 100 個の N-gram のみを特徴量として使用します。\n",
        "    \"\"\"\n",
        "    def add_ngram_features(df, column, ngram_range=(1, 2), max_features=50):  # max_features = 50\n",
        "\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=max_features)  # max_features を設定\n",
        "        # 既にクリーニング済みのカラムデータをそのまま使用\n",
        "        ngram_features = vectorizer.fit_transform(df[column])  # 変更箇所\n",
        "\n",
        "        # 特徴量名をデータフレームに追加\n",
        "        ngram_feature_names = vectorizer.get_feature_names_out()  # 抽出された特徴量の名前を取得します。\n",
        "        for i, feature_name in enumerate(ngram_feature_names):\n",
        "            # 抽出された各 N-gram 特徴量を、新しいカラムとしてデータフレームに追加します。\n",
        "            df[f'{column}_ngram_{feature_name}'] = ngram_features[:, i].toarray().ravel()\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    # TF-IDF（単語頻度-逆文書頻度）特徴量を追加する関数(定義)\n",
        "    \"\"\"\n",
        "    TF-IDFベクトライザーの適用: TfidfVectorizerを使用して、テキストデータをTF-IDF値に基づいた数値ベクトルに変換します。\n",
        "\n",
        "    max_features=1000で出現頻度が高い上位1000単語のみを特徴量として使用します。\n",
        "    stop_words='english'で英語のストップワードを削除します。\n",
        "    特徴量の次元削減: TruncatedSVDを使用して、TF-IDF特徴量の次元数を削減します。\n",
        "\n",
        "    n_components=20で次元数を20に削減します。\n",
        "    random_state=42で結果の再現性を確保します。\n",
        "    特徴量をデータフレームに追加: 生成されたTF-IDF特徴量は、trainとtestデータフレームに新しいカラムとして追加されます。\n",
        "\n",
        "    関数の適用: add_tfidf_features関数を'Positive_Review'と'Negative_Review'カラムに適用し、TF-IDF特徴量を追加します。\n",
        "    \"\"\"\n",
        "    def add_tfidf_features(train, test, column, n_components=100, max_features=100):\n",
        "\n",
        "        # TF-IDFベクトライザーの適用\n",
        "        tfidf = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
        "        tfidf_train = tfidf.fit_transform(train[column])\n",
        "        tfidf_test = tfidf.transform(test[column])\n",
        "\n",
        "        # 特徴量の次元削減\n",
        "        svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "        svd_train = svd.fit_transform(tfidf_train)\n",
        "        svd_test = svd.transform(tfidf_test)\n",
        "\n",
        "        # 特徴量をデータフレームに追加\n",
        "        for i in range(n_components):\n",
        "            train[f'TFIDF_{column}_{i}'] = svd_train[:, i]\n",
        "            test[f'TFIDF_{column}_{i}'] = svd_test[:, i]\n",
        "\n",
        "        return train, test\n",
        "\n",
        "\n",
        "    # 埋め込み表現をデータフレームに追加する関数定義\n",
        "    # テキストを受け取り、その埋め込み表現を返す関数を定義\n",
        "    def add_embedding_features(df, column, model_name='glove-wiki-gigaword-100', max_features=50): # max_features を引数に追加\n",
        "\n",
        "        # glove-wiki-gigaword-100 という名前の事前学習済みモデル (GloVe) を読み込みます。\n",
        "        # このモデルは、Wikipediaなどの大規模なテキストデータから単語の埋め込み表現を学習しています。\n",
        "        model = api.load(model_name)  # 事前学習済みモデルの読み込み\n",
        "\n",
        "        # テキストを受け取り、その埋め込み表現を返す関数を定義\n",
        "        def get_embedding(text):\n",
        "            words = text.split()    # テキストを単語に分割\n",
        "            embeddings = [model[word] for word in words if word in model]   #各単語の埋め込み表現を事前学習済みモデルから取得\n",
        "\n",
        "            if embeddings:          # 単語の埋め込み表現が存在する場合、それらを平均してテキスト全体の埋め込み表現を計算\n",
        "                return np.mean(embeddings, axis=0)\n",
        "            else:                   # 単語の埋め込み表現が存在しない場合、ゼロベクトルを返す\n",
        "                return np.zeros(model.vector_size)\n",
        "\n",
        "        # get_embedding 関数を df の指定された column ( 'Positive_Review' または 'Negative_Review' ) に適用し、\n",
        "        # 埋め込み表現をデータフレームに変換する\n",
        "        embedding_features = df[column].apply(get_embedding).apply(pd.Series)\n",
        "\n",
        "        # 埋め込み表現の特徴量数を max_features で指定された数に制限します。\n",
        "        embedding_features = embedding_features.iloc[:, :max_features] # 列数を制限\n",
        "\n",
        "        # 埋め込み表現のカラムに名前を付けます (例: 'Positive_Review_embedding_0', 'Positive_Review_embedding_1', ...)。\n",
        "        embedding_features.columns = [f'{column}_embedding_{i}' for i in range(embedding_features.shape[1])]\n",
        "\n",
        "        # 埋め込み表現を元のデータフレームに結合します。\n",
        "        df = pd.concat([df, embedding_features], axis=1)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "    # 極性と主観性をデータフレームに追加する関数の定義 合計4カラム追加される。\n",
        "    def add_polarity_features(df, column):\n",
        "\n",
        "        # TextBlob を使って、指定された column ( 'Positive_Review' または 'Negative_Review' ) のテキストの極性を計算し、{column}_polarity という名前の新しいカラムに追加します。\n",
        "        df[f'{column}_polarity'] = df[column].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "        # 同様に、主観性を計算し、{column}_subjectivity という名前の新しいカラムに追加します。\n",
        "        df[f'{column}_subjectivity'] = df[column].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 5種の関数を呼び出す ['Positive_Review', 'Negative_Review']の二回\n",
        "    \"\"\"\n",
        "    add_ngram_features 関数: データフレーム df に直接カラムを追加するため、return df がなくても元のデータフレームに反映される。\n",
        "    add_embedding_features 関数: 新しいデータフレームを作成して df に代入するため、return df で更新された df を返す必要がある。\n",
        "    \"\"\"\n",
        "    for col in columns:\n",
        "\n",
        "        # add_bow_features関数実行\n",
        "        train, test = add_bow_features(train, test, col, max_features=100)\n",
        "        print(f\"add_bow_features  : {datetime.now()} - End \")\n",
        "        print(f\"train : {train.shape} - End\")\n",
        "        print(f\"test : {test.shape} - End\")\n",
        "\n",
        "        # N-gram 特徴量を抽出関数実行\n",
        "        train = add_ngram_features(train, col, max_features=100)    # 使用例: 上位 〇〇 個の Ngram 特徴量のみを追加\n",
        "        test = add_ngram_features(test, col, max_features=100)     # 使用例: 上位 〇〇 個の Ngram 特徴量のみを追加\n",
        "        print(f\"add_ngram_features : {datetime.now()} - End\")\n",
        "        print(f\"train : {train.shape} - End\")\n",
        "        print(f\"test : {test.shape} - End\")\n",
        "\n",
        "        # TF-IDF特徴量追加関数実行\n",
        "        train, test = add_tfidf_features(train, test, col, max_features=100)\n",
        "        print(f\"add_tfidf_features : {datetime.now()} - End\")\n",
        "        print(f\"train : {train.shape} - End\")\n",
        "        print(f\"test : {test.shape} - End\")\n",
        "\n",
        "        # 埋め込み表現追加関数実行\n",
        "        train = add_embedding_features(train, col, max_features=100)\n",
        "        test = add_embedding_features(test, col, max_features=100)\n",
        "        print(f\"add_embedding_features : {datetime.now()} - End\")\n",
        "        print(f\"train : {train.shape} - End\")\n",
        "        print(f\"test : {test.shape} - End\")\n",
        "\n",
        "        # 極性と主観性を追加する関数実行\n",
        "        train = add_polarity_features(train, col)\n",
        "        test = add_polarity_features(test, col)\n",
        "        print(f\"add_polarity_features : {datetime.now()} - End\")\n",
        "        print(f\"train : {train.shape} - End\")\n",
        "        print(f\"test : {test.shape} - End\")\n",
        "\n",
        "        print(f\"{col} : {datetime.now()} - End\")\n",
        "\n",
        "    # preprocess_reviews関数終わり\n",
        "    return train, test\n",
        "\n",
        "# preprocess_reviews関数の実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train, test = preprocess_reviews(train, test, review_columns)\n",
        "\n",
        "\n",
        "# キーワードを抽出し、特徴量として追加する関数\n",
        "def preprocess_reviews2(df, max_features=100):\n",
        "    def extract_keywords(text):\n",
        "        words = text.lower().split()\n",
        "        common_words = ['the', 'and', 'is', 'in', 'it', 'to', 'was', 'i', 'of', 'a', 'this']\n",
        "        keywords = [word for word in words if word not in common_words]\n",
        "        return ' '.join(keywords)\n",
        "\n",
        "    df['Positive_Review_Keywords'] = df['Positive_Review'].apply(extract_keywords)\n",
        "    df['Negative_Review_Keywords'] = df['Negative_Review'].apply(extract_keywords)\n",
        "\n",
        "    # CountVectorizerを使ってキーワードをエンコード（フィーチャースペースを制限）\n",
        "    vectorizer = CountVectorizer(max_features=max_features)\n",
        "\n",
        "    positive_keywords_matrix = vectorizer.fit_transform(df['Positive_Review_Keywords'])\n",
        "    negative_keywords_matrix = vectorizer.fit_transform(df['Negative_Review_Keywords'])\n",
        "\n",
        "    # スパース行列を結合\n",
        "    keywords_matrix = hstack([positive_keywords_matrix, negative_keywords_matrix])\n",
        "\n",
        "    # スパース行列をデータフレームに変換する\n",
        "    keywords_df = pd.DataFrame(keywords_matrix.toarray(), columns=[f'Keyword_{i}' for i in range(keywords_matrix.shape[1])])\n",
        "\n",
        "    # 元のデータフレームに結合\n",
        "    df = pd.concat([df.reset_index(drop=True), keywords_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    return df\n",
        "# キーワードを抽出し、特徴量として追加する関数の実行\n",
        "train = preprocess_reviews2(train, max_features=100)\n",
        "test = preprocess_reviews2(test, max_features=100)\n",
        "print(f\"preprocess_reviews2 : {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessingTime: {processing_time}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "49hSgOoNQgRE",
        "outputId": "d588a1c9-2a7c-401b-dde2-fd3d236031e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2024-11-26 10:40:36.990274\n",
            "train : (283366, 886) - \n",
            "test : (231845, 873) - \n",
            "extract_date_features End:  2024-11-26 10:40:42.827047 - End\n",
            "train : (283366, 890) - End\n",
            "test : (231845, 877) - End\n",
            "add_interaction_features : 2024-11-26 10:40:42.912177 - End\n",
            "train : (283366, 890) - End\n",
            "test : (231845, 877) - End\n",
            "preprocess_hotel_names End:  2024-11-26 10:40:43.121043 - End\n",
            "train : (283366, 890) - End\n",
            "test : (231845, 877) - End\n",
            "preprocess_lat_lng End:  2024-11-26 10:40:43.964765 - End\n",
            "train : (283366, 890) - End\n",
            "test : (231845, 877) - End\n",
            "distance_from_landmark : 2024-11-26 10:43:34.264866 - End\n",
            "train : (283366, 890) - End\n",
            "test : (231845, 877) - End\n",
            "preprocess_data End:  2024-11-26 10:45:52.771819 - End\n",
            "train : (283366, 897) - End\n",
            "test : (231845, 895) - End\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\n",
            "add_readalility_features:  2024-11-26 10:46:27.381466 - End\n",
            "train : (283366, 899) - End\n",
            "test : (231845, 897) - End\n",
            "add_clustering_features :  2024-11-26 10:46:45.414340 - End\n",
            "train : (283366, 901) - End\n",
            "test : (231845, 899) - End\n",
            "add_tag_embeddings :  2024-11-26 10:47:22.968434 - End\n",
            "train : (283366, 951) - End\n",
            "test : (231845, 949) - End\n",
            "add_tag_clusters :  2024-11-26 10:47:25.931027 - End\n",
            "train : (283366, 952) - End\n",
            "test : (231845, 950) - End\n",
            "End  : 2024-11-26 10:47:25.931533\n",
            "ProcessTime: 0:06:48.941259\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'peint' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-39aded23e010>\u001b[0m in \u001b[0;36m<cell line: 283>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0mprocessing_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ProcessTime: {processing_time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m \u001b[0mpeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train : {train.shape} - End\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test : {test.shape} - End\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'peint' is not defined"
          ]
        }
      ],
      "source": [
        "#Review項目以外の特徴量追加\n",
        "#レビュー日付、ホテル名、緯度経度といった情報から新しい特徴量を生成\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "print(f\"train : {train.shape} - \")\n",
        "print(f\"test : {test.shape} - \")\n",
        "\n",
        "\n",
        "#### レビュー日付からの特徴量生成(定義)#####\n",
        "def extract_date_features(df, date_column):\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "    df['Review_weekday'] = df[date_column].dt.weekday   #レビューが投稿された曜日 (0:月曜日, 1:火曜日, ..., 6:日曜日)\n",
        "    df['Review_month'] = df[date_column].dt.month       #レビューが投稿された月 (1:1月, 2:2月, ..., 12:12月)\n",
        "    df['Review_quarter'] = df[date_column].dt.quarter   #レビューが投稿された四半期 (1:1-3月, 2:4-6月, 3:7-9月, 4:10-12月)\n",
        "    df['Review_season'] = df[date_column].dt.month % 12 // 3 + 1    #レビューが投稿された季節 (1:春, 2:夏, 3:秋, 4:冬)\n",
        "    df['Review_hour'] = df[date_column].dt.hour       #投稿時間帯を抽出（朝、昼、夜など）\n",
        "    df['Review_TimeOfDay'] = pd.cut(df['Review_hour'], bins=[0, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n",
        "    df = pd.get_dummies(df, columns=['Review_TimeOfDay'])   #ワンホット\n",
        "    return df\n",
        "# 3．レビュー日付からの特徴量生成(実行)\n",
        "date_column = 'Review_Date'\n",
        "train = extract_date_features(train, date_column)\n",
        "test = extract_date_features(test, date_column)\n",
        "print(f\"extract_date_features End:  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "############################################\n",
        "\n",
        "### 既存の特徴量の積や商などの相互作用項を生成###\n",
        "def add_interaction_features(df, columns):\n",
        "    for i in range(len(columns)):\n",
        "        for j in range(i + 1, len(columns)):\n",
        "            col1 = columns[i]\n",
        "            col2 = columns[j]\n",
        "            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]\n",
        "            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)  # ゼロ除算を防ぐために小さな値を追加\n",
        "    return df\n",
        "# 実行\n",
        "numeric_columns = ['Review_hour', 'Review_weekday', 'Review_month', 'Review_quarter', 'Review_season']\n",
        "train = add_interaction_features(train, numeric_columns)\n",
        "test = add_interaction_features(test, numeric_columns)\n",
        "print(f\"add_interaction_features : {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "#################################################\n",
        "\n",
        "### ホテル名の処理(定義) ########################\n",
        "def preprocess_hotel_names(train, test, column):\n",
        "    train[f'{column}_length'] = train[column].apply(len)    #Hotel_Name_length: ホテル名の文字数\n",
        "    test[f'{column}_length'] = test[column].apply(len)      #Hotel_Name_length: ホテル名の文字数\n",
        "    train[f'{column}_frequency'] = train[column].map(train[column].value_counts())  #Hotel_Name_frequency: データセット全体におけるそのホテル名の出現頻度\n",
        "    test[f'{column}_frequency'] = test[column].map(train[column].value_counts())    #Hotel_Name_frequency: データセット全体におけるそのホテル名の出現頻度\n",
        "    return train, test\n",
        "# 4．ホテル名の処理(実行)\n",
        "hotel_name_column = 'Hotel_Name'\n",
        "train, test = preprocess_hotel_names(train, test, hotel_name_column)\n",
        "print(f\"preprocess_hotel_names End:  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "#################################################\n",
        "\n",
        "### 5. 緯度・経度の組み合わせ(定義)##############\n",
        "#機械学習モデルがホテルの位置情報をより効果的に利用できるようにするために設計\n",
        "#train、testに、lat_lng と lat_lng_encoded という2つの新しいカラムを追加する\n",
        "\"\"\"\n",
        "1.緯度経度の結合:\n",
        "lat カラム（緯度）と lng カラム（経度）の値を文字列に変換し、\"_\" で連結して新しい lat_lng カラムを作成します。\n",
        "例えば、緯度が35.6895、経度が139.6917の場合、lat_lng カラムの値は \"35.6895_139.6917\" となります。\n",
        "これにより、緯度と経度を組み合わせた単一の特徴量が生成されます。\n",
        "2.ラベルエンコーディング:\n",
        "LabelEncoder を使用して、lat_lng カラムの値を数値に変換します。\n",
        "LabelEncoder は、カテゴリカルデータを数値に変換する際に使用される手法です。\n",
        "fit_transform メソッドを使用して、train データフレームの lat_lng カラムに含まれるユニークな値にそれぞれ数値を割り当てます。\n",
        "transform メソッドを使用して、test データフレームの lat_lng カラムの値を、train データフレームで割り当てられた数値に変換します。\n",
        "これにより、lat_lng_encoded という新しいカラムが作成され、緯度経度の組み合わせが数値で表現されます。\n",
        "\"\"\"\n",
        "def preprocess_lat_lng(train, test, lat_column, lng_column):\n",
        "    # K-meansクラスタリングの代わりに、簡単な組み合わせ特徴量を作成\n",
        "    train['lat_lng'] = train[lat_column].astype(str) + '_' + train[lng_column].astype(str)\n",
        "    test['lat_lng'] = test[lat_column].astype(str) + '_' + test[lng_column].astype(str)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    train['lat_lng_encoded'] = encoder.fit_transform(train['lat_lng'])\n",
        "    test['lat_lng_encoded'] = encoder.transform(test['lat_lng'])\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# 5．緯度・経度の組み合わせ(実行)\n",
        "lat_column = 'lat'\n",
        "lng_column = 'lng'\n",
        "train, test = preprocess_lat_lng(train, test, lat_column, lng_column)\n",
        "print(f\"preprocess_lat_lng End:  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "###################################################\n",
        "\n",
        "### ロンドン中心部からの距離#######################\n",
        "def distance_from_landmark(train, test):\n",
        "    # 主要ランドマークの緯度経度（例: ロンドン中心部）\n",
        "    landmark_coords = (51.5074, -0.1278)\n",
        "    # 有効な緯度と経度の平均を計算する\n",
        "    mean_lat = train['lat'].dropna().mean()\n",
        "    mean_lng = train['lng'].dropna().mean()\n",
        "    # NaN 値を平均値で埋める\n",
        "    train['lat'].fillna(mean_lat, inplace=True)\n",
        "    train['lng'].fillna(mean_lng, inplace=True)\n",
        "    # テストデータセットにも同じ処理を行う\n",
        "    test['lat'].fillna(mean_lat, inplace=True)\n",
        "    test['lng'].fillna(mean_lng, inplace=True)\n",
        "    # 距離を計算\n",
        "    train['Distance_To_Landmark'] = train.apply(lambda row: geodesic((row['lat'], row['lng']), landmark_coords).km, axis=1)\n",
        "    test['Distance_To_Landmark'] = test.apply(lambda row: geodesic((row['lat'], row['lng']), landmark_coords).km, axis=1)\n",
        "    return train, test\n",
        "# 実行\n",
        "train,test = distance_from_landmark(train, test)\n",
        "print(f\"distance_from_landmark : {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "##################################################\n",
        "\n",
        "\n",
        "###一番古いコーディング部分#######################\n",
        "def preprocess_data(df):\n",
        "\n",
        "    # レビューの文字数を計算する\n",
        "    df['Positive_Review_Length'] = df['Positive_Review'].apply(len)\n",
        "    df['Negative_Review_Length'] = df['Negative_Review'].apply(len)\n",
        "\n",
        "    # 単語数のカウント\n",
        "    df['Positive_Review_text_length_word'] = df['Positive_Review'].apply(lambda x: len(x.split()))\n",
        "    df['Negative_Review_text_length_word'] = df['Negative_Review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # レビューのポジティブ・ネガティブ比率\n",
        "    df['Review_Word_Ratio'] = df['Positive_Review_Length'] / (df['Negative_Review_Length'] + 1)\n",
        "\n",
        "    # VADERを使ったセンチメント分析\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    df['Positive_Review_Sentiment'] = df['Positive_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "    df['Negative_Review_Sentiment'] = df['Negative_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "\n",
        "    # 過去のレビュー数と平均スコア\n",
        "    df['Reviews_Per_Hotel'] = df.groupby('Hotel_Name')['Total_Number_of_Reviews'].transform('sum')\n",
        "    df['Average_Score_Per_Hotel'] = df.groupby('Hotel_Name')['Average_Score'].transform('mean')\n",
        "\n",
        "    # ホテルのレビュー数の変化\n",
        "    df['Review_Trend'] = df.groupby('Hotel_Name')['Total_Number_of_Reviews'].transform(lambda x: x.diff().fillna(0))\n",
        "    df['Average_Score_Trend'] = df.groupby('Hotel_Name')['Average_Score'].transform(lambda x: x.diff().fillna(0))\n",
        "\n",
        "    # レビュアーのアクティブ度\n",
        "    df['Reviewer_Activity'] = df['Total_Number_of_Reviews_Reviewer_Has_Given'] / df['days_since_review'].apply(lambda x: int(x.split()[0]))\n",
        "\n",
        "    # 月ごとの宿泊者満足度\n",
        "    if 'Reviewer_Score' in df.columns:\n",
        "        df['Monthly_Avg_Score'] = df.groupby('Review_month')['Reviewer_Score'].transform('mean')\n",
        "\n",
        "    # 否定的・肯定的なレビューの有無\n",
        "    df['Has_Negative_Review'] = df['Negative_Review'].apply(lambda x: 1 if x.strip() else 0)\n",
        "    df['Has_Positive_Review'] = df['Positive_Review'].apply(lambda x: 1 if x.strip() else 0)\n",
        "\n",
        "    # レビュアーの詳細情報解析\n",
        "    df['Trip_Type'] = df['Tags'].apply(lambda x: 1 if 'Leisure trip' in x else 0)\n",
        "    df['With_Family'] = df['Tags'].apply(lambda x: 1 if 'Family with young children' in x or 'Family with older children' in x else 0)\n",
        "    df['With_Partner'] = df['Tags'].apply(lambda x: 1 if 'Couple' in x else 0)\n",
        "    df['Solo_Traveler'] = df['Tags'].apply(lambda x: 1 if 'Solo traveler' in x else 0)\n",
        "\n",
        "    return df\n",
        "\n",
        "#一番古いコーディング部分の実行\n",
        "train = preprocess_data(train)\n",
        "test = preprocess_data(test)\n",
        "print(f\"preprocess_data End:  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "#################################################\n",
        "\n",
        "\n",
        "### テキストの読みやすさ指標 ####################\n",
        "!pip install textstat\n",
        "from textstat import textstat\n",
        "# テキストの読みやすさ指標を追加\n",
        "def add_readability_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_flesch_reading_ease'] = df[col].apply(lambda x: textstat.flesch_reading_ease(x) if pd.notnull(x) else 0)\n",
        "    return df\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_readability_features(train, review_columns)\n",
        "test = add_readability_features(test, review_columns)\n",
        "print(f\"add_readalility_features:  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "##################################################\n",
        "\n",
        "###クラスタリングによる特徴量#####################\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "# テキストデータを数値ベクトルに変換してからクラスタリングを行います\n",
        "def add_clustering_features(df, columns, n_clusters=5):\n",
        "    for col in columns:\n",
        "        # TF-IDFベクトル化\n",
        "        tfidf_vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = tfidf_vectorizer.fit_transform(df[col].fillna(''))\n",
        "\n",
        "        # KMeansクラスタリング\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        df[f'{col}_cluster'] = kmeans.fit_predict(tfidf_matrix)\n",
        "    return df\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_clustering_features(train, review_columns)\n",
        "test = add_clustering_features(test, review_columns)\n",
        "print(f\"add_clustering_features :  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "######################################################\n",
        "\"\"\"\n",
        "#エンティティ認識　→時間かかる\n",
        "import spacy\n",
        "\n",
        "# SpaCyを使用してエンティティを抽出し、特徴量として追加\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def add_entity_features(df, columns):\n",
        "    for col in columns:\n",
        "        df[f'{col}_entities'] = df[col].apply(lambda x: ' '.join([ent.label_ for ent in nlp(x).ents]) if pd.notnull(x) else '')\n",
        "    return df\n",
        "# 実行\n",
        "review_columns = ['Positive_Review', 'Negative_Review']\n",
        "train = add_entity_features(train, review_columns)\n",
        "test = add_entity_features(test, review_columns)\n",
        "print(f\"add_entity features :  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### タグの埋め込み表現 ######################################\n",
        "from gensim.models import Word2Vec\n",
        "def add_tag_embeddings(df, tag_column, vector_size=50):\n",
        "    tags = df[tag_column].dropna().apply(lambda x: x.split(',')).tolist()\n",
        "    model = Word2Vec(tags, vector_size=vector_size, window=5, min_count=1, sg=1)\n",
        "    def get_tag_vector(tags):\n",
        "        tag_vecs = [model.wv[tag] for tag in tags if tag in model.wv]\n",
        "        if tag_vecs:\n",
        "            return np.mean(tag_vecs, axis=0)\n",
        "        else:\n",
        "            return np.zeros(vector_size)\n",
        "    tag_vectors = df[tag_column].apply(lambda x: get_tag_vector(x.split(',')) if pd.notnull(x) else np.zeros(vector_size))\n",
        "    tag_vectors_df = pd.DataFrame(tag_vectors.tolist(), index=df.index)\n",
        "    return pd.concat([df, tag_vectors_df], axis=1)\n",
        "#実行\n",
        "train = add_tag_embeddings(train, 'Tags')\n",
        "test = add_tag_embeddings(test, 'Tags')\n",
        "print(f\"add_tag_embeddings :  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "#################################################################\n",
        "\n",
        "### タグのクラスタリング ########################################\n",
        "from sklearn.cluster import KMeans\n",
        "def add_tag_clusters(df, tag_column, n_clusters=5):\n",
        "    vectorizer = CountVectorizer(tokenizer=lambda x: x.split(','))\n",
        "    tag_matrix = vectorizer.fit_transform(df[tag_column].fillna(''))\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(tag_matrix)\n",
        "    df[tag_column + '_cluster'] = kmeans.labels_\n",
        "    return df\n",
        "#実行\n",
        "train = add_tag_clusters(train, 'Tags')\n",
        "test = add_tag_clusters(test, 'Tags')\n",
        "print(f\"add_tag_clusters :  {datetime.now()} - End\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "##################################################################\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End  : {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "print(f\"train : {train.shape} - End\")\n",
        "print(f\"test : {test.shape} - End\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYLWwxfjReWs",
        "outputId": "5616bd5c-c0c0-463b-a558-0c51dd79d822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(283366, 952)\n",
            "(231845, 950)\n"
          ]
        }
      ],
      "source": [
        "#6まで全体のバックアップ取得\n",
        "train_bkup6 = train.copy()\n",
        "test_bkup6 = test.copy()\n",
        "\n",
        "print(train_bkup6.shape)\n",
        "print(test_bkup6.shape)\n",
        "\n",
        "#(283366, 952)\n",
        "#(231845, 950)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4ddnBwQZ-jn"
      },
      "outputs": [],
      "source": [
        "#バックアップから戻す\n",
        "train = train_bkup6.copy()\n",
        "test = test_bkup6.copy()\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XScmbuIHdpD",
        "outputId": "8bcf2621-e8b9-4672-b038-dbbdea98192d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2024-11-26 10:49:51.917684\n",
            "Fold 1 Start:2024-11-26 10:50:03.934891\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[260]\tvalid_0's rmse: 1.01274\n",
            "Fold 1 LightGBM time:2024-11-26 10:53:13.376130\n",
            "Fold 1 XGBoost time:2024-11-26 11:02:47.508602\n",
            "Fold 1 CatBoost time:2024-11-26 11:04:20.830033\n",
            "Fold 1 RMSE (LightGBM): 1.0127\n",
            "Fold 1 RMSE (XGBoost): 1.0098\n",
            "Fold 1 RMSE (CatBoost): 1.0156\n",
            "Fold 2 Start:2024-11-26 11:04:29.577631\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[248]\tvalid_0's rmse: 1.01213\n",
            "Fold 2 LightGBM time:2024-11-26 11:07:30.307716\n",
            "Fold 2 XGBoost time:2024-11-26 11:17:12.463886\n",
            "Fold 2 CatBoost time:2024-11-26 11:18:53.094951\n",
            "Fold 2 RMSE (LightGBM): 1.0121\n",
            "Fold 2 RMSE (XGBoost): 1.0081\n",
            "Fold 2 RMSE (CatBoost): 1.0168\n",
            "Fold 3 Start:2024-11-26 11:19:02.229089\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[189]\tvalid_0's rmse: 1.01001\n",
            "Fold 3 LightGBM time:2024-11-26 11:21:40.848398\n",
            "Fold 3 XGBoost time:2024-11-26 11:33:06.831949\n",
            "Fold 3 CatBoost time:2024-11-26 11:34:47.615416\n",
            "Fold 3 RMSE (LightGBM): 1.0100\n",
            "Fold 3 RMSE (XGBoost): 1.0051\n",
            "Fold 3 RMSE (CatBoost): 1.0144\n",
            "Fold 4 Start:2024-11-26 11:34:55.659836\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[265]\tvalid_0's rmse: 1.01628\n",
            "Fold 4 LightGBM time:2024-11-26 11:38:06.691916\n",
            "Fold 4 XGBoost time:2024-11-26 11:49:27.644216\n",
            "Fold 4 CatBoost time:2024-11-26 11:51:06.907733\n",
            "Fold 4 RMSE (LightGBM): 1.0163\n",
            "Fold 4 RMSE (XGBoost): 1.0136\n",
            "Fold 4 RMSE (CatBoost): 1.0206\n",
            "Fold 5 Start:2024-11-26 11:51:16.162163\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[217]\tvalid_0's rmse: 1.00663\n",
            "Fold 5 LightGBM time:2024-11-26 11:54:06.653272\n",
            "Fold 5 XGBoost time:2024-11-26 12:05:37.334764\n",
            "Fold 5 CatBoost time:2024-11-26 12:07:16.244154\n",
            "Fold 5 RMSE (LightGBM): 1.0066\n",
            "Fold 5 RMSE (XGBoost): 1.0035\n",
            "Fold 5 RMSE (CatBoost): 1.0100\n",
            "Mean RMSE (LightGBM): 1.0116\n",
            "Mean RMSE (XGBoost): 1.0080\n",
            "Mean RMSE (CatBoost): 1.0155\n",
            "End: 2024-11-26 12:07:25.837532\n",
            "ProcessTime: 1:17:33.919848\n"
          ]
        }
      ],
      "source": [
        "#アンサンブルコード書き直し　11月25日\n",
        "#ランダムフォレスト除外\n",
        "#3つのモデルのハイパーパラメータ変更\n",
        "################################################################\n",
        "\"\"\"\n",
        "from datetime import datetime\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "# 必要なモジュールのインポートを追加→結局使わない\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "# 訓練用データセットの数値型以外の列を削除する\n",
        "train = train.select_dtypes(include=['int64', 'float64', 'int32'])\n",
        "\n",
        "# 推論用データセットにもレビュースコア以外の同様の列を残す\n",
        "test = test[[col for col in train.columns if col in test.columns]]\n",
        "\n",
        "# 訓練用データセットからターゲットを分離する\n",
        "X = train.drop('Reviewer_Score', axis=1)\n",
        "y = train['Reviewer_Score']\n",
        "\n",
        "# テストデータに存在しない列を追加して0で埋める\n",
        "missing_cols = set(X.columns) - set(test.columns)\n",
        "for col in missing_cols:\n",
        "    test[col] = 0\n",
        "\n",
        "\n",
        "# 列の順番を訓練データと同じにする\n",
        "test = test[X.columns]\n",
        "\n",
        "# 無限大の値を置換\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# 欠損値を平均値で補完 (他の方法でも補完可能)\n",
        "X = X.fillna(X.mean())            #平均値で埋める\n",
        "test = test.fillna(test.mean())\n",
        "# 例：X_train = X_train.dropna()  # NaN値を含む行を削除\n",
        "\n",
        "# float64に型変換\n",
        "X = X.astype(np.float64)\n",
        "test = test.astype(np.float64)\n",
        "\n",
        "\n",
        "# KFoldによる分割設定\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 結果を保存するリスト\n",
        "rmses = []\n",
        "test_preds_lgb = np.zeros(test.shape[0])\n",
        "test_preds_rf = np.zeros(test.shape[0])\n",
        "test_preds_xgb = np.zeros(test.shape[0])\n",
        "test_preds_cat = np.zeros(test.shape[0])\n",
        "\n",
        "# 各モデルの最適なハイパーパラメータの設定\n",
        "lgb_params = {\n",
        "    'learning_rate': 0.0992812083091482,   #0.05から変更\n",
        "    'min_child_samples': 80,    #61から変更\n",
        "    'n_estimators': 1000,   #500から変更\n",
        "    'num_leaves': 228,      #250から変更\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': -1,\n",
        "    'random_state': 42,\n",
        "    'lambda_l1': 8.20347685605361e-08,  #追加\n",
        "    'lambda_l2': 0.7381607235798092,    #追加\n",
        "    'feature_fraction': 0.5402252647925102, #追加\n",
        "    'bagging_fraction': 0.9979505273736299, #追加\n",
        "    'bagging_freq': 6                      #追加\n",
        "    }\n",
        "\n",
        "\"\"\"\n",
        "Optunaで算出したパラメータ\n",
        "Best parameters: {'learning_rate': 0.0992812083091482, 'num_leaves': 250, 'min_child_samples': 61}\n",
        "Best RMSE: 1.012224322083124\n",
        "\n",
        "こちらもOptunaで算出したパラメータ(11月26日)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'lambda_l1': 8.20347685605361e-08,\n",
        "    'lambda_l2': 0.7381607235798092,\n",
        "    'num_leaves': 228,\n",
        "    'feature_fraction': 0.5402252647925102,\n",
        "    'bagging_fraction': 0.9979505273736299,\n",
        "    'bagging_freq': 6,\n",
        "    'min_child_samples': 80\n",
        "}\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "rf_params = {\n",
        "    'n_estimators': 25, #ランダムフォレストを構成する決定木の数,100〜200 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'random_state': 42, #乱数シード\n",
        "    'max_depth': 10,    #各決定木の最大深さ None（制限なし）から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'min_samples_split': 2, #ノードを分割するために必要な最小サンプル数 2〜10 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    'min_samples_leaf': 1,  #葉ノードに存在する最小サンプル数 1〜5 程度から始め、交差検証などで最適な値を探索するのが良い\n",
        "    #'max_features': 'auto',    #各決定木でノードを分割する際に考慮する特徴量の最大数 'auto'（特徴量の数の平方根）、'sqrt'、'log2' など\n",
        "    'n_jobs': -1    #並列処理に使用するコア数  -1 を指定すると、すべてのコアを使用\n",
        "}\n",
        "\"\"\"\n",
        "xgb_params = {\n",
        "    'learning_rate': 0.1,  #デフォルトは0.3　一般的に、0.01〜0.1程度の値が使用される。\n",
        "    'n_estimators': 1000,    #ブースター（決定木）の数\n",
        "    'objective': 'reg:squarederror',    #reg:squarederror（回帰）\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "cat_params = {\n",
        "    'iterations': 500,      #学習の反復回数 (決定木の数)\n",
        "    'learning_rate': 0.1,   #学習率\n",
        "    'depth': 6,             #決定木の最大深度\n",
        "    'loss_function': 'RMSE',#損失関数\n",
        "    'random_seed': 42,      #乱数シード\n",
        "    'verbose': 0            #学習過程の出力レベル　0表示なし　1表示あり\n",
        "}\n",
        "\n",
        "# 各foldでの訓練と評価\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold+1} Start:{datetime.now()}\")\n",
        "\n",
        "    # 訓練用データと検証用データに分割\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "\n",
        "    # LightGBMモデルの訓練\n",
        "    lgb_model = lgb.train(\n",
        "        lgb_params,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "    print(f\"Fold {fold+1} LightGBM time:{datetime.now()}\")\n",
        "\n",
        "\n",
        "    # XGBoostモデルの訓練\n",
        "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "    early_stop = EarlyStopping(rounds=50) # EarlyStoppingコールバックを作成\n",
        "    #xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], callbacks=[early_stop], verbose=False) # callbacks引数に追加\n",
        "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
        "    print(f\"Fold {fold+1} XGBoost time:{datetime.now()}\")\n",
        "\n",
        "    # CatBoostモデルの訓練\n",
        "    cat_model = CatBoostRegressor(**cat_params)\n",
        "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=50, verbose=False)\n",
        "    print(f\"Fold {fold+1} CatBoost time:{datetime.now()}\")\n",
        "\n",
        "    # ランダムフォレストモデルの訓練\n",
        "    #rf_model = RandomForestRegressor(**rf_params)\n",
        "    #rf_model.fit(X_train, y_train)\n",
        "    #print(f\"Fold {fold+1} ランダムフォレスト time:{datetime.now()}\")\n",
        "\n",
        "\n",
        "    # 検証用データセットに対する予測\n",
        "    y_pred_lgb = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "    y_pred_xgb = xgb_model.predict(X_valid)\n",
        "    y_pred_cat = cat_model.predict(X_valid)\n",
        "    #y_pred_rf = rf_model.predict(X_valid)\n",
        "\n",
        "    # モデルの性能をRMSEで評価\n",
        "    rmse_lgb = mean_squared_error(y_valid, y_pred_lgb, squared=False)\n",
        "    rmse_xgb = mean_squared_error(y_valid, y_pred_xgb, squared=False)\n",
        "    rmse_cat = mean_squared_error(y_valid, y_pred_cat, squared=False)\n",
        "    #rmse_rf = mean_squared_error(y_valid, y_pred_rf, squared=False)\n",
        "    print(f\"Fold {fold+1} RMSE (LightGBM): {rmse_lgb:.4f}\")\n",
        "    print(f\"Fold {fold+1} RMSE (XGBoost): {rmse_xgb:.4f}\")\n",
        "    print(f\"Fold {fold+1} RMSE (CatBoost): {rmse_cat:.4f}\")\n",
        "    #print(f\"Fold {fold+1} RMSE (RandomForest): {rmse_rf:.4f}\")\n",
        "\n",
        "    # 各foldの結果を保存\n",
        "    #rmses.append((rmse_lgb, rmse_rf, rmse_xgb, rmse_cat))\n",
        "    rmses.append((rmse_lgb, rmse_xgb, rmse_cat))\n",
        "\n",
        "    # テストデータに対する予測を平均\n",
        "    test_preds_lgb += lgb_model.predict(test, num_iteration=lgb_model.best_iteration) / kf.n_splits\n",
        "    test_preds_xgb += xgb_model.predict(test) / kf.n_splits\n",
        "    test_preds_cat += cat_model.predict(test) / kf.n_splits\n",
        "    #test_preds_rf += rf_model.predict(test) / kf.n_splits\n",
        "\n",
        "# 全体の平均RMSE\n",
        "mean_rmse_lgb = sum([rmse[0] for rmse in rmses]) / len(rmses)\n",
        "mean_rmse_xgb = sum([rmse[1] for rmse in rmses]) / len(rmses)\n",
        "mean_rmse_cat = sum([rmse[2] for rmse in rmses]) / len(rmses)\n",
        "#mean_rmse_rf = sum([rmse[3] for rmse in rmses]) / len(rmses)\n",
        "\n",
        "print(f\"Mean RMSE (LightGBM): {mean_rmse_lgb:.4f}\")\n",
        "print(f\"Mean RMSE (XGBoost): {mean_rmse_xgb:.4f}\")\n",
        "print(f\"Mean RMSE (CatBoost): {mean_rmse_cat:.4f}\")\n",
        "#print(f\"Mean RMSE (RandomForest): {mean_rmse_rf:.4f}\")\n",
        "\n",
        "# アンサンブル予測の平均\n",
        "#final_test_preds = (test_preds_lgb + test_preds_rf + test_preds_xgb + test_preds_cat) / 4\n",
        "final_test_preds = (test_preds_lgb + test_preds_xgb + test_preds_cat) / 3\n",
        "\n",
        "# 予測結果を保存する\n",
        "submit = pd.read_csv('/content/drive/MyDrive/data/sample_submission.csv', header=None)\n",
        "submit[1] = final_test_preds\n",
        "submit.to_csv('/content/drive/MyDrive/data/submit_ensemble.csv', header=None, index=False)\n",
        "\n",
        "submit.head()\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6m2wTB9lhHC"
      },
      "outputs": [],
      "source": [
        "\"\"\"コピー用\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_pbMHmqfO65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e3675a-fea5-4b7c-aaa6-9c85a720c68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: 2024-11-26 12:39:16.074740\n",
            "Fold 1 Start:2024-11-26 12:39:25.838479\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[204]\tvalid_0's rmse: 1.01632\n",
            "Fold 1 LightGBM time:2024-11-26 12:43:15.728005\n",
            "Fold 1 RMSE (LightGBM): 1.0163\n",
            "Fold 2 Start:2024-11-26 12:43:20.450952\n",
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        }
      ],
      "source": [
        "### LightGBMのみ。1回目の下位20％カラムを削除して\n",
        "### 2回目のLightGBMを実施する\n",
        "######################################################\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"Start: {start_time}\")\n",
        "\n",
        "# 訓練用データセットの数値型以外の列を削除する\n",
        "train = train.select_dtypes(include=['int64', 'float64', 'int32'])\n",
        "\n",
        "# 推論用データセットにもレビュースコア以外の同様の列を残す\n",
        "test = test[[col for col in train.columns if col in test.columns]]\n",
        "\n",
        "# 訓練用データセットからターゲットを分離する\n",
        "X = train.drop('Reviewer_Score', axis=1)\n",
        "y = train['Reviewer_Score']\n",
        "\n",
        "# テストデータに存在しない列を追加して0で埋める\n",
        "missing_cols = set(X.columns) - set(test.columns)\n",
        "for col in missing_cols:\n",
        "    test[col] = 0\n",
        "\n",
        "# 列の順番を訓練データと同じにする\n",
        "test = test[X.columns]\n",
        "\n",
        "# 無限大の値を置換\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# 欠損値を平均値で補完 (他の方法でも補完可能)\n",
        "X = X.fillna(X.mean())            #平均値で埋める\n",
        "test = test.fillna(test.mean())\n",
        "# 例：X_train = X_train.dropna()  # NaN値を含む行を削除\n",
        "\n",
        "# float64に型変換\n",
        "X = X.astype(np.float64)\n",
        "test = test.astype(np.float64)\n",
        "\n",
        "# KFoldによる分割設定\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 結果を保存するリスト\n",
        "rmses = []\n",
        "test_preds_lgb = np.zeros(test.shape[0])\n",
        "\n",
        "# 各モデルの最適なハイパーパラメータの設定\n",
        "\n",
        "lgb_params = {\n",
        "    'learning_rate': 0.0992812083091482,   #0.05から変更\n",
        "    'min_child_samples': 61,    #\n",
        "    'n_estimators': 1000,   #500から変更\n",
        "    'num_leaves': 250,\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': -1,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "\n",
        "# 各foldでの訓練と評価\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold+1} Start:{datetime.now()}\")\n",
        "\n",
        "    # 訓練用データと検証用データに分割\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "\n",
        "    # LightGBMモデルの訓練\n",
        "    lgb_model = lgb.train(\n",
        "        lgb_params,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "    print(f\"Fold {fold+1} LightGBM time:{datetime.now()}\")\n",
        "\n",
        "\n",
        "    # 検証用データセットに対する予測\n",
        "    y_pred_lgb = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "\n",
        "    # モデルの性能をRMSEで評価\n",
        "    rmse_lgb = mean_squared_error(y_valid, y_pred_lgb, squared=False)\n",
        "    print(f\"Fold {fold+1} RMSE (LightGBM): {rmse_lgb:.4f}\")\n",
        "\n",
        "    # 各foldの結果を保存\n",
        "    rmses.append((rmse_lgb,))    # 単一要素のタプルとして追加\n",
        "\n",
        "    # テストデータに対する予測を平均\n",
        "    test_preds_lgb += lgb_model.predict(test, num_iteration=lgb_model.best_iteration) / kf.n_splits\n",
        "\n",
        "# 全体の平均RMSE\n",
        "mean_rmse_lgb = sum([rmse[0] for rmse in rmses]) / len(rmses)\n",
        "\n",
        "print(f\"Mean RMSE (LightGBM): {mean_rmse_lgb:.4f}\")\n",
        "\n",
        "# アンサンブル予測の平均\n",
        "final_test_preds = (test_preds_lgb) / 1\n",
        "\n",
        "# 予測結果を保存する\n",
        "submit = pd.read_csv('/content/drive/MyDrive/data/sample_submission.csv', header=None)\n",
        "submit[1] = final_test_preds\n",
        "submit.to_csv('/content/drive/MyDrive/data/submit_LightGBM1.csv', header=None, index=False)\n",
        "\n",
        "submit.head()\n",
        "\n",
        "\n",
        "# 特徴量重要度を取得\n",
        "feature_importance = lgb_model.feature_importance()  # 既存のモデルから重要度を取得\n",
        "feature_importance_df = pd.DataFrame({'feature': lgb_model.feature_name(), 'importance': feature_importance})\n",
        "\n",
        "# 重要度でソート\n",
        "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
        "feature_importance_df.to_csv('/content/drive/MyDrive/data/feature_importance.csv', index=False)\n",
        "\n",
        "# ランキングを表示\n",
        "print(feature_importance_df)  # DataFrame全体を表示\n",
        "\n",
        "# 上位N件のみ表示したい場合 (例: 上位50件)\n",
        "N = 50\n",
        "print(feature_importance_df.head(N))\n",
        "\n",
        "# 重要度の低い特徴量を削除 (例: 重要度が下位20%の特徴量を削除)\n",
        "threshold = feature_importance_df['importance'].quantile(0.2)\n",
        "selected_features = feature_importance_df[feature_importance_df['importance'] > threshold]['feature'].tolist()\n",
        "\n",
        "# selected_features に含まれるカラムが X に存在するか確認\n",
        "# 存在しないカラムがあれば警告を表示し、selected_features から削除\n",
        "missing_features = [f for f in selected_features if f not in X.columns]\n",
        "if missing_features:\n",
        "    print(f\"警告: 以下の特徴量は X に存在しません: {missing_features}\")\n",
        "    selected_features = [f for f in selected_features if f in X.columns]\n",
        "\n",
        "\n",
        "# 選択された特徴量のみでデータを準備\n",
        "X_selected = X[selected_features]  # Xは特徴量データ\n",
        "test_selected = test[selected_features]\n",
        "\n",
        "# test_selected に不足している列を取得する\n",
        "missing_cols = set(X_selected.columns) - set(test_selected.columns)\n",
        "\n",
        "# test_selected に不足している列を追加し、0 で埋める\n",
        "for col in missing_cols:\n",
        "    test[col] = 0\n",
        "\n",
        "# 列の順序が同じであることを確認する\n",
        "test_selected = test_selected[X_selected.columns]\n",
        "\n",
        "\n",
        "# KFoldによる分割設定\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 結果を保存するリスト\n",
        "rmses = []\n",
        "test_preds = np.zeros(test_selected.shape[0])\n",
        "\n",
        "# 各foldでの訓練と評価(2回目)\n",
        "for fold, (train_index, valid_index) in enumerate(kf.split(X)):\n",
        "    print(f\"2回目のFold {fold+1} Start:{datetime.now()}\")\n",
        "\n",
        "    # 訓練用データと検証用データに分割 (選択された特徴量を使用)\n",
        "    X_train, X_valid = X_selected.iloc[train_index], X_selected.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]  # yはターゲット変数\n",
        "\n",
        "    # LightGBM用のデータセットに変換 (選択された特徴量を使用)\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
        "\n",
        "\n",
        "    # LightGBMモデルの訓練\n",
        "    lgb_model = lgb.train(\n",
        "        lgb_params,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "    print(f\"2回目のFold {fold+1} LightGBM time:{datetime.now()}\")\n",
        "\n",
        "\n",
        "    # 検証用データセットに対する予測\n",
        "    y_pred_lgb = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "\n",
        "    # モデルの性能をRMSEで評価\n",
        "    rmse_lgb = mean_squared_error(y_valid, y_pred_lgb, squared=False)\n",
        "    print(f\"2回目のFold {fold+1} RMSE (LightGBM): {rmse_lgb:.4f}\")\n",
        "\n",
        "    # 各foldの結果を保存\n",
        "    rmses.append((rmse_lgb,))    # 単一要素のタプルとして追加\n",
        "\n",
        "    # テストデータに対する予測を平均\n",
        "    test_preds_lgb += lgb_model.predict(test_selected, num_iteration=lgb_model.best_iteration) / kf.n_splits\n",
        "\n",
        "# 全体の平均RMSE\n",
        "mean_rmse_lgb = sum([rmse[0] for rmse in rmses]) / len(rmses)\n",
        "\n",
        "print(f\"2回目のMean RMSE (LightGBM): {mean_rmse_lgb:.4f}\")\n",
        "\n",
        "# アンサンブル予測の平均\n",
        "final_test_preds = (test_preds_lgb) / 1\n",
        "\n",
        "# 予測結果を保存する\n",
        "submit = pd.read_csv('/content/drive/MyDrive/data/sample_submission.csv', header=None)\n",
        "submit[1] = final_test_preds\n",
        "submit.to_csv('/content/drive/MyDrive/data/submit_LightGBM2.csv', header=None, index=False)\n",
        "feature_importance_df.to_csv('/content/drive/MyDrive/data/feature_importance.csv', index=False)\n",
        "submit.head()\n",
        "\n",
        "# 処理時間を計算\n",
        "end_time = datetime.now()\n",
        "print(f\"End: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfOhXUIh4vgv"
      },
      "source": [
        "以降は、チューニング用のモジュール\n",
        "Optuna、"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gF3MazO8eIqi",
        "outputId": "5f4ed24d-ff0e-4b95-e550-b916c734ef0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:53:32,922] A new study created in memory with name: no-name-3fa18244-f329-4b45-a380-e7b52f25a9b3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:53:58,381] Trial 0 finished with value: 1.0209939024421686 and parameters: {'lambda_l1': 0.044491794413784105, 'lambda_l2': 0.024717005701910138, 'num_leaves': 142, 'feature_fraction': 0.6806528670096379, 'bagging_fraction': 0.719084062008787, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 0 with value: 1.0209939024421686.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:54:31,578] Trial 1 finished with value: 1.0191193141238468 and parameters: {'lambda_l1': 0.044175628220094805, 'lambda_l2': 6.392126560265532e-05, 'num_leaves': 167, 'feature_fraction': 0.7982469577892992, 'bagging_fraction': 0.9299810165520934, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 1 with value: 1.0191193141238468.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:54:48,706] Trial 2 finished with value: 1.0254502522594624 and parameters: {'lambda_l1': 0.011399026705832595, 'lambda_l2': 1.1328370821508709e-08, 'num_leaves': 90, 'feature_fraction': 0.5135883381384826, 'bagging_fraction': 0.45450944253711817, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 1 with value: 1.0191193141238468.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:55:23,781] Trial 3 finished with value: 1.0230555897095979 and parameters: {'lambda_l1': 0.8731949365014041, 'lambda_l2': 3.1736063709819744, 'num_leaves': 231, 'feature_fraction': 0.8295155785066174, 'bagging_fraction': 0.5458413557846153, 'bagging_freq': 1, 'min_child_samples': 23}. Best is trial 1 with value: 1.0191193141238468.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:55:39,992] Trial 4 finished with value: 1.0256217654988378 and parameters: {'lambda_l1': 2.4120854624245168e-05, 'lambda_l2': 6.178945759637442e-06, 'num_leaves': 104, 'feature_fraction': 0.4291345075635332, 'bagging_fraction': 0.4179240508914737, 'bagging_freq': 3, 'min_child_samples': 73}. Best is trial 1 with value: 1.0191193141238468.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:56:07,316] Trial 5 finished with value: 1.0190112297043472 and parameters: {'lambda_l1': 3.6285431611188277, 'lambda_l2': 6.528017019489647, 'num_leaves': 122, 'feature_fraction': 0.7589061710237972, 'bagging_fraction': 0.8523397816062153, 'bagging_freq': 6, 'min_child_samples': 79}. Best is trial 5 with value: 1.0190112297043472.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:56:28,024] Trial 6 finished with value: 1.0263256044017948 and parameters: {'lambda_l1': 0.3460084134224698, 'lambda_l2': 0.0006136083237093881, 'num_leaves': 75, 'feature_fraction': 0.7842429000148632, 'bagging_fraction': 0.5362032462072801, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 5 with value: 1.0190112297043472.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:56:49,079] Trial 7 finished with value: 1.02515599626101 and parameters: {'lambda_l1': 1.8036533279482025e-06, 'lambda_l2': 3.98589819790554, 'num_leaves': 67, 'feature_fraction': 0.7219550278416337, 'bagging_fraction': 0.8089463890322326, 'bagging_freq': 7, 'min_child_samples': 95}. Best is trial 5 with value: 1.0190112297043472.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.03581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:57:03,656] Trial 8 finished with value: 1.0358091642767655 and parameters: {'lambda_l1': 6.40776124069132e-08, 'lambda_l2': 4.037208685348284e-06, 'num_leaves': 30, 'feature_fraction': 0.6907498741116757, 'bagging_fraction': 0.44462439282931526, 'bagging_freq': 2, 'min_child_samples': 88}. Best is trial 5 with value: 1.0190112297043472.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:57:32,710] Trial 9 finished with value: 1.0173324611353898 and parameters: {'lambda_l1': 1.5090116553124008e-07, 'lambda_l2': 0.0005190363976477774, 'num_leaves': 245, 'feature_fraction': 0.5676381394204565, 'bagging_fraction': 0.9381632641876494, 'bagging_freq': 3, 'min_child_samples': 87}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:58:18,097] Trial 10 finished with value: 1.018182509356961 and parameters: {'lambda_l1': 1.4531328464792591e-08, 'lambda_l2': 0.012908312053092992, 'num_leaves': 254, 'feature_fraction': 0.9649194423678268, 'bagging_fraction': 0.9833901281896108, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:59:03,668] Trial 11 finished with value: 1.019305890090457 and parameters: {'lambda_l1': 1.710664432328e-08, 'lambda_l2': 0.0088969968753949, 'num_leaves': 254, 'feature_fraction': 0.9671600649755232, 'bagging_fraction': 0.9992674382496431, 'bagging_freq': 4, 'min_child_samples': 46}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:59:30,663] Trial 12 finished with value: 1.0181261007765674 and parameters: {'lambda_l1': 5.560433165050467e-07, 'lambda_l2': 0.03617643364903989, 'num_leaves': 200, 'feature_fraction': 0.5549305429272228, 'bagging_fraction': 0.9964124665300444, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 03:59:57,377] Trial 13 finished with value: 1.020024738422199 and parameters: {'lambda_l1': 1.1529797417105155e-06, 'lambda_l2': 0.11633821254989425, 'num_leaves': 186, 'feature_fraction': 0.596324375315392, 'bagging_fraction': 0.8600945614642537, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's rmse: 1.02058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:00:24,678] Trial 14 finished with value: 1.0205776860303346 and parameters: {'lambda_l1': 0.00029807187638612146, 'lambda_l2': 0.0012169338186117215, 'num_leaves': 202, 'feature_fraction': 0.5591299220708028, 'bagging_fraction': 0.7204765605997587, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 9 with value: 1.0173324611353898.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:00:46,341] Trial 15 finished with value: 1.0170310905978552 and parameters: {'lambda_l1': 9.338022113992554e-07, 'lambda_l2': 3.752492708281283e-05, 'num_leaves': 208, 'feature_fraction': 0.410556580130481, 'bagging_fraction': 0.9124172870906022, 'bagging_freq': 3, 'min_child_samples': 97}. Best is trial 15 with value: 1.0170310905978552.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:01:07,794] Trial 16 finished with value: 1.018885149328319 and parameters: {'lambda_l1': 1.7740941690526497e-05, 'lambda_l2': 1.7352505475232177e-07, 'num_leaves': 222, 'feature_fraction': 0.4052959186502699, 'bagging_fraction': 0.7945349300868958, 'bagging_freq': 2, 'min_child_samples': 97}. Best is trial 15 with value: 1.0170310905978552.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:01:29,413] Trial 17 finished with value: 1.0185330395022083 and parameters: {'lambda_l1': 4.051959057717988e-05, 'lambda_l2': 2.4270605024533562e-05, 'num_leaves': 156, 'feature_fraction': 0.46893938171030924, 'bagging_fraction': 0.9112745749134777, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 15 with value: 1.0170310905978552.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.0268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:01:58,269] Trial 18 finished with value: 1.0268030207504448 and parameters: {'lambda_l1': 0.0010982947728549017, 'lambda_l2': 7.807360524100401e-07, 'num_leaves': 226, 'feature_fraction': 0.6346304274505686, 'bagging_fraction': 0.6374204983493812, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 15 with value: 1.0170310905978552.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:02:21,148] Trial 19 finished with value: 1.0167327601540184 and parameters: {'lambda_l1': 1.885778102950025e-07, 'lambda_l2': 8.527344124008364e-05, 'num_leaves': 176, 'feature_fraction': 0.49084658772915934, 'bagging_fraction': 0.9060464959471761, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:02:43,211] Trial 20 finished with value: 1.0188759565317083 and parameters: {'lambda_l1': 2.7357357521834703e-06, 'lambda_l2': 7.760588607074863e-05, 'num_leaves': 179, 'feature_fraction': 0.4881157172488024, 'bagging_fraction': 0.7839580332849714, 'bagging_freq': 5, 'min_child_samples': 100}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:03:07,416] Trial 21 finished with value: 1.0170145042672525 and parameters: {'lambda_l1': 1.2871062005230298e-07, 'lambda_l2': 0.0017095833195704222, 'num_leaves': 215, 'feature_fraction': 0.4584829212927107, 'bagging_fraction': 0.9264582888336373, 'bagging_freq': 5, 'min_child_samples': 85}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:03:32,068] Trial 22 finished with value: 1.0187226179666282 and parameters: {'lambda_l1': 2.824672202655028e-07, 'lambda_l2': 0.0020891310589761544, 'num_leaves': 208, 'feature_fraction': 0.4361240852145698, 'bagging_fraction': 0.8818312179054992, 'bagging_freq': 5, 'min_child_samples': 91}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:03:56,323] Trial 23 finished with value: 1.0180412528176195 and parameters: {'lambda_l1': 5.600606926963223e-06, 'lambda_l2': 0.00014818561856214292, 'num_leaves': 150, 'feature_fraction': 0.5079515248087294, 'bagging_fraction': 0.832290664694846, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:04:16,957] Trial 24 finished with value: 1.019559725219325 and parameters: {'lambda_l1': 6.487944564610419e-08, 'lambda_l2': 1.381575997639631e-05, 'num_leaves': 182, 'feature_fraction': 0.40447066094741907, 'bagging_fraction': 0.9448276966293567, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:04:37,769] Trial 25 finished with value: 1.018234448944873 and parameters: {'lambda_l1': 0.00016854929120404229, 'lambda_l2': 0.3956994271051539, 'num_leaves': 132, 'feature_fraction': 0.4662335624891191, 'bagging_fraction': 0.8992596427381998, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:05:02,035] Trial 26 finished with value: 1.01823158739776 and parameters: {'lambda_l1': 6.698923987537001e-08, 'lambda_l2': 1.136396210743079e-06, 'num_leaves': 213, 'feature_fraction': 0.5142450007970889, 'bagging_fraction': 0.7397626474237482, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:05:26,042] Trial 27 finished with value: 1.0225777082108753 and parameters: {'lambda_l1': 5.913290224795841e-06, 'lambda_l2': 0.0020361950586164253, 'num_leaves': 163, 'feature_fraction': 0.6247817037660645, 'bagging_fraction': 0.6206319606546535, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:05:48,524] Trial 28 finished with value: 1.0182788309947028 and parameters: {'lambda_l1': 1.0819339844078256e-08, 'lambda_l2': 0.00022573851688018686, 'num_leaves': 194, 'feature_fraction': 0.4517725325706868, 'bagging_fraction': 0.9561990384993858, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:06:14,174] Trial 29 finished with value: 1.0204788439244734 and parameters: {'lambda_l1': 3.63742780324603e-07, 'lambda_l2': 0.004123754051404089, 'num_leaves': 236, 'feature_fraction': 0.5464785700735493, 'bagging_fraction': 0.6783049059741432, 'bagging_freq': 6, 'min_child_samples': 93}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:06:43,977] Trial 30 finished with value: 1.0199809504364734 and parameters: {'lambda_l1': 0.0032442436903391686, 'lambda_l2': 8.014305296864768e-08, 'num_leaves': 135, 'feature_fraction': 0.8625284805801835, 'bagging_fraction': 0.8918531997185318, 'bagging_freq': 5, 'min_child_samples': 66}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:07:13,811] Trial 31 finished with value: 1.016764987855073 and parameters: {'lambda_l1': 2.2422665260645052e-07, 'lambda_l2': 0.0003914057300186153, 'num_leaves': 243, 'feature_fraction': 0.5832207705317011, 'bagging_fraction': 0.9461487350382453, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:07:44,315] Trial 32 finished with value: 1.0178839613425232 and parameters: {'lambda_l1': 8.483654378985087e-07, 'lambda_l2': 4.374245326022575e-05, 'num_leaves': 222, 'feature_fraction': 0.6516612240612646, 'bagging_fraction': 0.9545466377670654, 'bagging_freq': 3, 'min_child_samples': 85}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:08:07,265] Trial 33 finished with value: 1.0199410892724587 and parameters: {'lambda_l1': 1.3103031903484444e-07, 'lambda_l2': 0.00015281256848092772, 'num_leaves': 174, 'feature_fraction': 0.5258576975340158, 'bagging_fraction': 0.7579696805894736, 'bagging_freq': 2, 'min_child_samples': 74}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:08:32,648] Trial 34 finished with value: 1.017437603769987 and parameters: {'lambda_l1': 3.6780744860733e-08, 'lambda_l2': 1.201216171163981e-05, 'num_leaves': 238, 'feature_fraction': 0.48956467627924366, 'bagging_fraction': 0.8506344285407677, 'bagging_freq': 3, 'min_child_samples': 94}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:09:01,400] Trial 35 finished with value: 1.017831183586751 and parameters: {'lambda_l1': 7.287671684420395e-05, 'lambda_l2': 2.6672948145812856e-06, 'num_leaves': 214, 'feature_fraction': 0.6041285379352564, 'bagging_fraction': 0.9233765886225712, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:09:20,062] Trial 36 finished with value: 1.0196601257485585 and parameters: {'lambda_l1': 7.038971908004562e-06, 'lambda_l2': 5.960822716558746e-05, 'num_leaves': 116, 'feature_fraction': 0.4404106538110544, 'bagging_fraction': 0.8796666243149089, 'bagging_freq': 1, 'min_child_samples': 71}. Best is trial 19 with value: 1.0167327601540184.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:09:45,615] Trial 37 finished with value: 1.0165332772316849 and parameters: {'lambda_l1': 3.015676050109237e-07, 'lambda_l2': 0.0006748439401290981, 'num_leaves': 166, 'feature_fraction': 0.5832763493364718, 'bagging_fraction': 0.9654822138379173, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:10:11,828] Trial 38 finished with value: 1.0181829540314056 and parameters: {'lambda_l1': 0.03479220735316915, 'lambda_l2': 0.046646624025113784, 'num_leaves': 167, 'feature_fraction': 0.5993665917436961, 'bagging_fraction': 0.9484841516216185, 'bagging_freq': 5, 'min_child_samples': 55}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:10:38,862] Trial 39 finished with value: 1.019384054799042 and parameters: {'lambda_l1': 2.2045126187632355e-07, 'lambda_l2': 0.0005865614522722353, 'num_leaves': 149, 'feature_fraction': 0.7196695367243022, 'bagging_fraction': 0.8239146728932916, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:10:50,401] Trial 40 finished with value: 1.1479940987009218 and parameters: {'lambda_l1': 3.391295065770988e-08, 'lambda_l2': 0.004924840142584357, 'num_leaves': 2, 'feature_fraction': 0.665433458100209, 'bagging_fraction': 0.973332422769642, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.14799\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:11:13,841] Trial 41 finished with value: 1.017015503311427 and parameters: {'lambda_l1': 2.027804338130079e-06, 'lambda_l2': 0.0004942528927336404, 'num_leaves': 191, 'feature_fraction': 0.4809119015495234, 'bagging_fraction': 0.9174516232407739, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:11:38,505] Trial 42 finished with value: 1.0183181542791402 and parameters: {'lambda_l1': 1.8535504700671884e-06, 'lambda_l2': 0.0007856736019920291, 'num_leaves': 186, 'feature_fraction': 0.5239299805058949, 'bagging_fraction': 0.925323588725235, 'bagging_freq': 4, 'min_child_samples': 33}. Best is trial 37 with value: 1.0165332772316849.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:12:05,454] Trial 43 finished with value: 1.0158502822878712 and parameters: {'lambda_l1': 1.6549226880035887e-07, 'lambda_l2': 0.0002692490200283684, 'num_leaves': 194, 'feature_fraction': 0.5778948445912598, 'bagging_fraction': 0.9738380706432521, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 43 with value: 1.0158502822878712.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:12:34,840] Trial 44 finished with value: 1.0175735536466548 and parameters: {'lambda_l1': 1.3300354364131617e-07, 'lambda_l2': 0.0002899928289172851, 'num_leaves': 241, 'feature_fraction': 0.5791053370687416, 'bagging_fraction': 0.9702898597188633, 'bagging_freq': 4, 'min_child_samples': 78}. Best is trial 43 with value: 1.0158502822878712.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's rmse: 1.02429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:12:56,208] Trial 45 finished with value: 1.0242867177925064 and parameters: {'lambda_l1': 4.7674903206816165e-07, 'lambda_l2': 0.012437146940222429, 'num_leaves': 169, 'feature_fraction': 0.5472866261333436, 'bagging_fraction': 0.5388786575183878, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 43 with value: 1.0158502822878712.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:13:20,553] Trial 46 finished with value: 1.0194236315991256 and parameters: {'lambda_l1': 2.2705633151962433e-08, 'lambda_l2': 0.002248036260378612, 'num_leaves': 108, 'feature_fraction': 0.6955878684749671, 'bagging_fraction': 0.9892789230555248, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 43 with value: 1.0158502822878712.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:13:56,690] Trial 47 finished with value: 1.018371711148811 and parameters: {'lambda_l1': 0.6497583732902801, 'lambda_l2': 0.00014298529688611017, 'num_leaves': 256, 'feature_fraction': 0.7547473128588901, 'bagging_fraction': 0.8586299563747949, 'bagging_freq': 2, 'min_child_samples': 86}. Best is trial 43 with value: 1.0158502822878712.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:14:24,119] Trial 48 finished with value: 1.015528154193077 and parameters: {'lambda_l1': 9.346374638490068e-08, 'lambda_l2': 0.4705962167971551, 'num_leaves': 197, 'feature_fraction': 0.5825760862421516, 'bagging_fraction': 0.9772610045824213, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:14:46,220] Trial 49 finished with value: 1.022285786203858 and parameters: {'lambda_l1': 1.7115246950432598e-05, 'lambda_l2': 1.2349801681612305, 'num_leaves': 85, 'feature_fraction': 0.6274734367068155, 'bagging_fraction': 0.969578356907081, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:15:08,612] Trial 50 finished with value: 1.0239828499166506 and parameters: {'lambda_l1': 7.150731594681298, 'lambda_l2': 6.109573668479349e-06, 'num_leaves': 198, 'feature_fraction': 0.5858837515344277, 'bagging_fraction': 0.48987328547442166, 'bagging_freq': 7, 'min_child_samples': 75}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.0163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:15:36,302] Trial 51 finished with value: 1.0163044608206353 and parameters: {'lambda_l1': 1.0972210350962926e-07, 'lambda_l2': 0.8378153714369776, 'num_leaves': 228, 'feature_fraction': 0.534607854780116, 'bagging_fraction': 0.9983070294191617, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:16:04,669] Trial 52 finished with value: 1.016239383516583 and parameters: {'lambda_l1': 4.7982041282808276e-08, 'lambda_l2': 1.3294913194131754, 'num_leaves': 234, 'feature_fraction': 0.5423609182748912, 'bagging_fraction': 0.9755698274168846, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:16:32,324] Trial 53 finished with value: 1.0162312721653042 and parameters: {'lambda_l1': 5.449714858612676e-08, 'lambda_l2': 1.127215985138959, 'num_leaves': 226, 'feature_fraction': 0.5352320178362029, 'bagging_fraction': 0.994089579398412, 'bagging_freq': 6, 'min_child_samples': 69}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:17:00,070] Trial 54 finished with value: 1.016582240592274 and parameters: {'lambda_l1': 5.052917199722456e-08, 'lambda_l2': 7.866824114074129, 'num_leaves': 225, 'feature_fraction': 0.5370270262857078, 'bagging_fraction': 0.9923137636931829, 'bagging_freq': 6, 'min_child_samples': 67}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:17:29,195] Trial 55 finished with value: 1.0160816655174603 and parameters: {'lambda_l1': 1.1358237713847208e-08, 'lambda_l2': 1.57130632846352, 'num_leaves': 229, 'feature_fraction': 0.5674456369769354, 'bagging_fraction': 0.992805491272335, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:17:58,106] Trial 56 finished with value: 1.0159379485035767 and parameters: {'lambda_l1': 1.1988782658078587e-08, 'lambda_l2': 2.018772088118309, 'num_leaves': 232, 'feature_fraction': 0.5658806595625262, 'bagging_fraction': 0.9991913555396972, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:18:30,296] Trial 57 finished with value: 1.016632320446663 and parameters: {'lambda_l1': 1.1473257647724876e-08, 'lambda_l2': 1.997574490009627, 'num_leaves': 248, 'feature_fraction': 0.6148880456724979, 'bagging_fraction': 0.975090466599613, 'bagging_freq': 7, 'min_child_samples': 50}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:18:58,212] Trial 58 finished with value: 1.0164110313636339 and parameters: {'lambda_l1': 2.7230083651557056e-08, 'lambda_l2': 0.2796597744170541, 'num_leaves': 204, 'feature_fraction': 0.5635748841298212, 'bagging_fraction': 0.9981673549429474, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:19:30,029] Trial 59 finished with value: 1.0184816913388322 and parameters: {'lambda_l1': 2.1636290377044056e-08, 'lambda_l2': 3.113318577145621, 'num_leaves': 233, 'feature_fraction': 0.6547970128030807, 'bagging_fraction': 0.9357919661761208, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.02391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:19:54,533] Trial 60 finished with value: 1.023914131887456 and parameters: {'lambda_l1': 1.1175439744192801e-08, 'lambda_l2': 0.11967367263069081, 'num_leaves': 218, 'feature_fraction': 0.5629929687929223, 'bagging_fraction': 0.5859522256855054, 'bagging_freq': 6, 'min_child_samples': 70}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:20:21,073] Trial 61 finished with value: 1.016911156615165 and parameters: {'lambda_l1': 7.555196322317959e-08, 'lambda_l2': 0.7653089620936765, 'num_leaves': 232, 'feature_fraction': 0.5041501631484686, 'bagging_fraction': 0.9894717080009661, 'bagging_freq': 6, 'min_child_samples': 76}. Best is trial 48 with value: 1.015528154193077.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's rmse: 1.01527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:20:48,894] Trial 62 finished with value: 1.0152721919279517 and parameters: {'lambda_l1': 8.20347685605361e-08, 'lambda_l2': 0.7381607235798092, 'num_leaves': 228, 'feature_fraction': 0.5402252647925102, 'bagging_fraction': 0.9979505273736299, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:21:16,290] Trial 63 finished with value: 1.0166654547331349 and parameters: {'lambda_l1': 4.026630470465045e-08, 'lambda_l2': 0.2355888757857852, 'num_leaves': 250, 'feature_fraction': 0.5070216943075936, 'bagging_fraction': 0.9609270395524958, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:21:44,965] Trial 64 finished with value: 1.0163543557553971 and parameters: {'lambda_l1': 2.1679228857173617e-08, 'lambda_l2': 4.288109125442791, 'num_leaves': 207, 'feature_fraction': 0.6087581345131952, 'bagging_fraction': 0.9443301618443009, 'bagging_freq': 7, 'min_child_samples': 72}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:22:15,838] Trial 65 finished with value: 1.0178738576103747 and parameters: {'lambda_l1': 8.906734608757211e-07, 'lambda_l2': 0.5157334950837777, 'num_leaves': 220, 'feature_fraction': 0.6368978023428211, 'bagging_fraction': 0.979091092624432, 'bagging_freq': 6, 'min_child_samples': 66}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:22:55,790] Trial 66 finished with value: 1.0190199136787033 and parameters: {'lambda_l1': 5.640057356116007e-08, 'lambda_l2': 0.09642482917324914, 'num_leaves': 243, 'feature_fraction': 0.8708225220067641, 'bagging_fraction': 0.8993459298005949, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:23:25,746] Trial 67 finished with value: 1.0175548082057477 and parameters: {'lambda_l1': 5.603074960589812e-07, 'lambda_l2': 9.899515843475056, 'num_leaves': 230, 'feature_fraction': 0.5697704306771962, 'bagging_fraction': 0.9372680914197203, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:23:53,292] Trial 68 finished with value: 1.0160056330774003 and parameters: {'lambda_l1': 1.0194330976663599e-07, 'lambda_l2': 2.0182773817911275, 'num_leaves': 208, 'feature_fraction': 0.5469200921010363, 'bagging_fraction': 0.960598832556203, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.03065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:24:08,895] Trial 69 finished with value: 1.030646695590967 and parameters: {'lambda_l1': 9.117397290988395e-08, 'lambda_l2': 2.308084500556251, 'num_leaves': 60, 'feature_fraction': 0.5533110843410015, 'bagging_fraction': 0.4015888506981894, 'bagging_freq': 7, 'min_child_samples': 13}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:24:41,689] Trial 70 finished with value: 1.0177285001133989 and parameters: {'lambda_l1': 1.829527487734075e-08, 'lambda_l2': 0.16076685627080875, 'num_leaves': 192, 'feature_fraction': 0.6681286601224383, 'bagging_fraction': 0.881888484928354, 'bagging_freq': 6, 'min_child_samples': 82}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:25:10,224] Trial 71 finished with value: 1.016176305324849 and parameters: {'lambda_l1': 1.0261048420958233e-08, 'lambda_l2': 1.2615051514709519, 'num_leaves': 211, 'feature_fraction': 0.5263157752640134, 'bagging_fraction': 0.9595336946023433, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:25:38,531] Trial 72 finished with value: 1.0172869412520802 and parameters: {'lambda_l1': 1.3197076291668516e-08, 'lambda_l2': 5.082765334907589, 'num_leaves': 213, 'feature_fraction': 0.513864037852613, 'bagging_fraction': 0.9618306045962057, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:26:04,477] Trial 73 finished with value: 1.0186465909663642 and parameters: {'lambda_l1': 1.7185559282675382e-07, 'lambda_l2': 0.05522964151693068, 'num_leaves': 198, 'feature_fraction': 0.4766939513275663, 'bagging_fraction': 0.9969778456057294, 'bagging_freq': 6, 'min_child_samples': 73}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.0173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:26:33,001] Trial 74 finished with value: 1.0172994469902983 and parameters: {'lambda_l1': 3.0232280427138644e-08, 'lambda_l2': 0.49605127911902075, 'num_leaves': 211, 'feature_fraction': 0.5969036320914127, 'bagging_fraction': 0.9137131286042689, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:27:01,130] Trial 75 finished with value: 1.0172677918838093 and parameters: {'lambda_l1': 8.698186159097395e-08, 'lambda_l2': 1.2318989329146628, 'num_leaves': 223, 'feature_fraction': 0.5672544909980627, 'bagging_fraction': 0.93214610571005, 'bagging_freq': 5, 'min_child_samples': 83}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:27:26,050] Trial 76 finished with value: 1.01747689624777 and parameters: {'lambda_l1': 3.908262947932849e-07, 'lambda_l2': 1.6961595777967222, 'num_leaves': 201, 'feature_fraction': 0.499095288763443, 'bagging_fraction': 0.9474782683118268, 'bagging_freq': 7, 'min_child_samples': 79}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:27:51,568] Trial 77 finished with value: 1.0159865191645454 and parameters: {'lambda_l1': 1.7625494795326892e-08, 'lambda_l2': 0.022387806734275317, 'num_leaves': 185, 'feature_fraction': 0.5385358766295921, 'bagging_fraction': 0.9784700030626378, 'bagging_freq': 5, 'min_child_samples': 70}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.0178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:28:17,026] Trial 78 finished with value: 1.017798420996431 and parameters: {'lambda_l1': 1.0981436944631999e-08, 'lambda_l2': 0.323260893810381, 'num_leaves': 182, 'feature_fraction': 0.5211950530422, 'bagging_fraction': 0.9589676073165034, 'bagging_freq': 5, 'min_child_samples': 60}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:28:40,544] Trial 79 finished with value: 1.0166181402841787 and parameters: {'lambda_l1': 2.0308328334732443e-08, 'lambda_l2': 0.022337321261571345, 'num_leaves': 195, 'feature_fraction': 0.4537625416269146, 'bagging_fraction': 0.982047116877503, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:29:01,872] Trial 80 finished with value: 1.0190170767378033 and parameters: {'lambda_l1': 0.0011901664467253176, 'lambda_l2': 2.8442634048897726, 'num_leaves': 189, 'feature_fraction': 0.4198989827154406, 'bagging_fraction': 0.8715769822287432, 'bagging_freq': 5, 'min_child_samples': 64}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:29:28,300] Trial 81 finished with value: 1.016263680127013 and parameters: {'lambda_l1': 3.9213395932573936e-08, 'lambda_l2': 0.6677646391227159, 'num_leaves': 206, 'feature_fraction': 0.5303240815886023, 'bagging_fraction': 0.9813731382440991, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.0207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:29:53,651] Trial 82 finished with value: 1.020697638053994 and parameters: {'lambda_l1': 7.325285894359228e-08, 'lambda_l2': 0.1979169405872002, 'num_leaves': 217, 'feature_fraction': 0.5504299877591536, 'bagging_fraction': 0.6841439598160646, 'bagging_freq': 6, 'min_child_samples': 68}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:30:23,308] Trial 83 finished with value: 1.0160328600946835 and parameters: {'lambda_l1': 1.915343502475992e-07, 'lambda_l2': 0.07509722849329309, 'num_leaves': 237, 'feature_fraction': 0.5779971795895719, 'bagging_fraction': 0.9569070226564573, 'bagging_freq': 6, 'min_child_samples': 77}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:31:07,727] Trial 84 finished with value: 1.0183557132644976 and parameters: {'lambda_l1': 1.9209076292429e-07, 'lambda_l2': 0.08842570962273488, 'num_leaves': 247, 'feature_fraction': 0.9923856981049974, 'bagging_fraction': 0.9545173892125813, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:31:33,607] Trial 85 finished with value: 1.0179295730824471 and parameters: {'lambda_l1': 1.0020288736184641e-08, 'lambda_l2': 0.031071437280690378, 'num_leaves': 176, 'feature_fraction': 0.5784940115046693, 'bagging_fraction': 0.9259167036811272, 'bagging_freq': 6, 'min_child_samples': 73}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:31:59,112] Trial 86 finished with value: 1.0185924072489936 and parameters: {'lambda_l1': 1.318345723493167e-07, 'lambda_l2': 5.5390904580118026, 'num_leaves': 159, 'feature_fraction': 0.5932154340459111, 'bagging_fraction': 0.9045776381370771, 'bagging_freq': 1, 'min_child_samples': 83}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:32:28,127] Trial 87 finished with value: 1.0176345606829218 and parameters: {'lambda_l1': 5.448014403360277e-07, 'lambda_l2': 0.06396906234527279, 'num_leaves': 209, 'feature_fraction': 0.6229832374924374, 'bagging_fraction': 0.9660774753643234, 'bagging_freq': 5, 'min_child_samples': 80}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's rmse: 1.01684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:32:53,915] Trial 88 finished with value: 1.0168427015937636 and parameters: {'lambda_l1': 3.543404950307438e-06, 'lambda_l2': 0.359964721428318, 'num_leaves': 242, 'feature_fraction': 0.4928274845218555, 'bagging_fraction': 0.9386019038298806, 'bagging_freq': 5, 'min_child_samples': 92}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:33:20,469] Trial 89 finished with value: 1.0167221279535206 and parameters: {'lambda_l1': 1.1720551174697786e-06, 'lambda_l2': 0.01676860646626564, 'num_leaves': 186, 'feature_fraction': 0.5759114938134624, 'bagging_fraction': 0.9801384852266452, 'bagging_freq': 6, 'min_child_samples': 87}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:33:50,864] Trial 90 finished with value: 1.016606363782331 and parameters: {'lambda_l1': 3.2595365838496426e-08, 'lambda_l2': 0.8407188693862173, 'num_leaves': 217, 'feature_fraction': 0.6450806459107596, 'bagging_fraction': 0.9162252782824027, 'bagging_freq': 6, 'min_child_samples': 57}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:34:18,887] Trial 91 finished with value: 1.0156773635886267 and parameters: {'lambda_l1': 1.8963642465202868e-08, 'lambda_l2': 1.1174509591426216, 'num_leaves': 239, 'feature_fraction': 0.5371045132463821, 'bagging_fraction': 0.9996544233237415, 'bagging_freq': 6, 'min_child_samples': 70}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:34:47,847] Trial 92 finished with value: 1.0187598869954362 and parameters: {'lambda_l1': 1.825344783903589e-08, 'lambda_l2': 2.055107025000684, 'num_leaves': 237, 'feature_fraction': 0.5567379403115061, 'bagging_fraction': 0.9546476998100912, 'bagging_freq': 6, 'min_child_samples': 71}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:35:15,794] Trial 93 finished with value: 1.0154429432978163 and parameters: {'lambda_l1': 2.7604799731642713e-07, 'lambda_l2': 0.5354642654899564, 'num_leaves': 251, 'feature_fraction': 0.5176787398728304, 'bagging_fraction': 0.9692099915520556, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:35:47,449] Trial 94 finished with value: 1.015856194873284 and parameters: {'lambda_l1': 2.6945594755497916e-07, 'lambda_l2': 0.14241872250685939, 'num_leaves': 256, 'feature_fraction': 0.6130922704620898, 'bagging_fraction': 0.9847376181756196, 'bagging_freq': 7, 'min_child_samples': 80}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:36:18,592] Trial 95 finished with value: 1.0168614925147454 and parameters: {'lambda_l1': 2.7337026257939194e-07, 'lambda_l2': 0.5165376398319127, 'num_leaves': 255, 'feature_fraction': 0.6080106992639625, 'bagging_fraction': 0.9997564847324648, 'bagging_freq': 7, 'min_child_samples': 81}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's rmse: 1.01565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:36:48,919] Trial 96 finished with value: 1.0156465281579001 and parameters: {'lambda_l1': 2.678436645896491e-07, 'lambda_l2': 0.14284754852298498, 'num_leaves': 252, 'feature_fraction': 0.5898253503953678, 'bagging_fraction': 0.9781805109287064, 'bagging_freq': 7, 'min_child_samples': 77}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:37:17,772] Trial 97 finished with value: 1.017053084172778 and parameters: {'lambda_l1': 0.08211093091000672, 'lambda_l2': 0.1437203531239443, 'num_leaves': 250, 'feature_fraction': 0.5450674148197272, 'bagging_fraction': 0.9741062187893564, 'bagging_freq': 7, 'min_child_samples': 80}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:37:47,896] Trial 98 finished with value: 1.0166708441065138 and parameters: {'lambda_l1': 1.4155005298236004e-06, 'lambda_l2': 0.008893426930857979, 'num_leaves': 248, 'feature_fraction': 0.5914052608870858, 'bagging_fraction': 0.9844178500517041, 'bagging_freq': 7, 'min_child_samples': 84}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's rmse: 1.01618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-26 04:38:19,061] Trial 99 finished with value: 1.0161808287095557 and parameters: {'lambda_l1': 3.6051843322058213e-07, 'lambda_l2': 0.24337960426765962, 'num_leaves': 253, 'feature_fraction': 0.6129936870281827, 'bagging_fraction': 0.9703636922832183, 'bagging_freq': 7, 'min_child_samples': 88}. Best is trial 62 with value: 1.0152721919279517.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 1.0152721919279517, params {'lambda_l1': 8.20347685605361e-08, 'lambda_l2': 0.7381607235798092, 'num_leaves': 228, 'feature_fraction': 0.5402252647925102, 'bagging_fraction': 0.9979505273736299, 'bagging_freq': 6, 'min_child_samples': 80}\n"
          ]
        }
      ],
      "source": [
        "#グリッドサーチとOptuna？\n",
        "#すごい時間かかった結果↓\n",
        "\"\"\"\n",
        "Best trial: score 1.0152721919279517,\n",
        "params {\n",
        "    'lambda_l1': 8.20347685605361e-08,\n",
        "    'lambda_l2': 0.7381607235798092,\n",
        "    'num_leaves': 228,\n",
        "    'feature_fraction': 0.5402252647925102,\n",
        "    'bagging_fraction': 0.9979505273736299,\n",
        "    'bagging_freq': 6,\n",
        "    'min_child_samples': 80\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "# TF-IDFベクトル化と感情分析の例\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "train_tfidf_pos = tfidf.fit_transform(train['Positive_Review'])\n",
        "train_tfidf_neg = tfidf.fit_transform(train['Negative_Review'])\n",
        "\n",
        "# 感情分析\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "train['Pos_Sentiment'] = train['Positive_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "train['Neg_Sentiment'] = train['Negative_Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "\n",
        "# 特徴量の結合\n",
        "X = hstack([train_tfidf_pos, train_tfidf_neg, train[['Average_Score', 'Total_Number_of_Reviews', 'Pos_Sentiment', 'Neg_Sentiment']]])\n",
        "y = train['Reviewer_Score']\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
        "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
        "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "    }\n",
        "\n",
        "    gbm = lgb.LGBMRegressor(**param)\n",
        "    gbm.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric='rmse', callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
        "    preds = gbm.predict(X_valid)\n",
        "    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXY9uWQi46Yt"
      },
      "source": [
        "GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxM7toEDI56K"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "#learning_rate, num_leaves, max_depthはモデルの性能に大きく影響するため、優先的にチューニングすることをお勧めします。\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの範囲を指定\n",
        "    param = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    # LightGBMモデルの学習\n",
        "    lgb_model = lgb.train(\n",
        "        param,\n",
        "        lgb.Dataset(X_train, label=y_train),\n",
        "        valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "\n",
        "    # 予測とRMSEの計算\n",
        "    y_pred = lgb_model.predict(X_valid, num_iteration=lgb_model.best_iteration)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse  # 最小化したい指標を返す\n",
        "\n",
        "study = optuna.create_study(direction='minimize')  # 最小化したい場合は 'minimize'\n",
        "study.optimize(objective, n_trials=100)  # 試行回数\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jymgDjuqNfqc"
      },
      "outputs": [],
      "source": [
        "start_time = datetime.now()\n",
        "print(f\"Start xgb_model: {start_time}\")\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    xgb_model = xgb.XGBRegressor(**param)\n",
        "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
        "\n",
        "    y_pred = xgb_model.predict(X_valid)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End xgb_model: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9r4QonPNhAV"
      },
      "outputs": [],
      "source": [
        "start_time = datetime.now()\n",
        "print(f\"Start Cat: {start_time}\")\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        # ... other hyperparameters ...\n",
        "    }\n",
        "\n",
        "    cat_model = CatBoostRegressor(**param, verbose=False)\n",
        "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
        "\n",
        "    y_pred = cat_model.predict(X_valid)\n",
        "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# 最適なハイパーパラメータ\n",
        "print(f\"Best parameters: {study.best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value}\")\n",
        "\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(f\"End cat: {end_time}\")\n",
        "processing_time = end_time - start_time\n",
        "print(f\"ProcessTime: {processing_time}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d-GrfcwWkZU"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
        "    }\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "    model = lgb.LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    mse = mean_squared_error(y_val, preds)\n",
        "    return mse\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best parameters: \", study.best_params)\n",
        "print(\"Best MSE: \", study.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b9mCfucL1KnG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ハイパーパラメータの候補を設定\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50, 70],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'min_child_samples': [20, 30, 50]\n",
        "}\n",
        "\n",
        "# LightGBMのモデルを設定\n",
        "lgb_model = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
        "\n",
        "# GridSearchCVを使用して最適なハイパーパラメータを探索\n",
        "grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# 最適なハイパーパラメータを表示\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjQ1mUbalLM5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNkcS9I5japHvhBI11DfCI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}